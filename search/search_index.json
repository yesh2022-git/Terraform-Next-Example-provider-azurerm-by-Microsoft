{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"AzureRM Provider Contributor Guides","text":"<p>First, thank you for your interest in contributing to the Azure Provider! And if you're unsure or anything, please do reach out for help. You can open a draft pull request (PR) or an issue with what you know or join the Slack Workspace for Contributors (Request Invite) and we'll do our best to guide you in the right direction.</p> <p>Note: this documentation is a work-in-progress - if you see something that's not quite right or missing, we'd really appreciate a PR!</p> <p>This contribution guide assumes you have at least a basic understanding of both Go and Terraform itself (for example you know what a Data Source and a Resource are) - more information on those can be found in the Terraform documentation.</p> <p>The AzureRM Provider is a Plugin which is invoked by Terraform (Core) and comprised of Data Sources and Resources.</p> <p>Within the AzureRM Provider, these Data Sources and Resources are grouped into Service Packages - which are logical groupings of Data Sources/Resources based on the Azure Service they're related to.</p> <p>Each of these Data Sources and Resources has both Acceptance Tests and Documentation associated with each Data Source/Resource - the Acceptance Tests are also located within this Service Package, however the Documentation exists within a dedicated folder.</p> <p>More granular documentation covers how these fit together - and the most common types of contribution we see:</p>"},{"location":"#topics","title":"Topics","text":"<p>Basics:</p> <ul> <li>High-level overview of the Provider</li> <li>Building the Provider</li> <li>Running the Tests</li> <li>Debugging the Provider</li> <li>Frequently Asked Questions</li> <li>Opening a PR</li> </ul> <p>Common Topics/Guides:</p> <ul> <li>Adding a new Service Package</li> <li>Adding a new Data Source</li> <li>Adding a new Resource</li> <li>Adding fields to an existing Data Source</li> <li>Adding fields to an existing Resource</li> <li>Adding State Migrations</li> <li>When to create a new Resource vs Inline Block</li> </ul> <p>References:</p> <ul> <li>Acceptance Testing</li> <li>Best Practices</li> <li>Glossary</li> <li>Naming</li> <li>Schema Design</li> <li>Working with Errors</li> </ul> <p>Maintainer specific:</p> <ul> <li>Updates to the Changelog</li> </ul>"},{"location":"topics/best-practices/","title":"Best Practices","text":"<p>Since it's inception the provider has undergone various iterations and changes in convention, as a result there can be legacy by-products within the provider which are inadvertently used as references. This section contains a miscellaneous assortment of current best practices to be aware of when contributing to the provider.</p>"},{"location":"topics/best-practices/#separate-create-and-update-methods","title":"Separate Create and Update Methods","text":"<p>Historically the Provider has opted to combine the Create and Update methods due to the behaviour of the Azure API, where the same API is used for both Create and Update, meaning that the same payload has to be sent during both the Creation and Update of the resource.</p> <p>In order to properly support Terraform's <code>ignore_changes</code> feature, rather than using a combined method for Create and Update, we're now requiring that these are separate, and that in the Update partial/delta differences are performed, to only update the value for a field if it's marked as changed.</p> <p>For example, whilst a Create method may look similar to below:</p> <pre><code>payload := resources.Group{\nLocation: location.Normalize(d.Get(\"location\").(string)),\nTags: tags.Expand(d.Get(\"tags\").(map[string]interface{}),\n}\nif err := client.CreateThenPoll(ctx, id, payload); err != nil {\nreturn fmt.Errorf(\"creating %s: %+v\", id, err)\n}\n</code></pre> <p>The update method should be checking if the updatable fields (in this example, only tags) - have changes (using <code>d.HasChanges</code> - which will flag updated values in the config if they're not ignored via <code>ignore_changes</code>).</p> <p>Depending on the API there are two types of Updates, a patch/delta update (where only the fields containing changes are sent) - and a full update (which requires sending the full payload) - these are differentiable via the method name in the SDK, patch/delta updates are generally called <code>Update</code>, with a full update being called <code>CreateOrUpdate</code>.</p> <p>A patch/delta update would look similar to below:</p> <pre><code>payload := resources.GroupUpdate{}\nif d.HasChanges(\"tags\") {\n// this uses `pointer.To` since all fields are optional in a patch/delta update, so they'll only be updated if specified\npayload.Tags = pointer.To(tags.Expand(d.Get(\"tags\").(map[string]interface{}))\n}\nif err := client.UpdateThenPoll(ctx, id, payload); err != nil {\nreturn fmt.Errorf(\"updating %s: %+v\", id, err)\n}\n</code></pre> <p>A full update would retrieve the existing object from the API and then patch it, for example:</p> <pre><code>resp, err := client.Get(ctx, id)\nif err != nil {\nreturn fmt.Errorf(\"retrieving %s: %+v\", id, err)\n}\nif resp.Model == nil {\nreturn fmt.Errorf(\"retrieving %s: model was nil\", id)\n}\npayload := *resp.Model\nif d.HasChanges(\"tags\") {\npayload.Tags = tags.Expand(d.Get(\"tags\").(map[string]interface{})\n}\nif err := client.UpdateThenPoll(ctx, id, payload); err != nil {\nreturn fmt.Errorf(\"updating %s: %+v\", id, err)\n}\n</code></pre>"},{"location":"topics/best-practices/#typed-vs-untyped-resources","title":"Typed vs. Untyped Resources","text":"<p>At this point in time the Provider supports Data Sources and Resources built using either the Typed SDK, or <code>hashicorp/terraform-plugin-sdk</code> (which we call <code>Untyped</code>). Whilst both of these output Terraform Data Sources and Resources, we're gradually moving from using Untyped Data Sources and Resources to Typed Resources since there's a number of advantages in doing so. We currently recommend using the internal sdk package to build Typed Resources.</p> <p>An example of both Typed and Untyped Resources can be found below - however as a general rule:</p> <ul> <li>When the Resource imports <code>\"github.com/hashicorp/terraform-provider-azurerm/internal/sdk\"</code> - it's using the Typed SDK.</li> <li>When the Resource doesn't import <code>\"github.com/hashicorp/terraform-provider-azurerm/internal/sdk\"</code> - then it's an Untyped Resource, which is backed by <code>hashicorp/terraform-plugin-sdk</code>.</li> </ul> <p>Data Sources and Resources built using the Typed SDK have a number of benefits over those using <code>hashicorp/terraform-plugin-sdk</code> directly:</p> <ul> <li>The Typed SDK requires that a number of Azure specific behaviours are present in each Data Source/Resource. For example, the <code>interface</code> defining the Typed SDK includes a <code>IDValidationFunc()</code> function, which is used during <code>terraform import</code> to ensure the Resource ID being specified matches what we're expecting. Whilst this is possible using the Untyped SDK, it's more work to do so, as such using the Typed SDK ensures that these behaviours become common across the provider.</li> <li>The Typed SDK exposes an <code>Encode()</code> and <code>Decode()</code> method, allowing the marshalling/unmarshalling of the Terraform Configuration into a Go Object - which both:<ol> <li>Avoids logic errors when an incorrect key is used in <code>d.Get</code> and <code>d.Set</code>, since we can (TODO: https://github.com/hashicorp/terraform-provider-azurerm/blob/5652afa601d33368ebefb4a549584e214e9729cb/internal/sdk/wrapper_validate.go#L21) validate that each of the HCL keys used for the models (to get and set these from the Terraform Config) is present within the Schema via a unit test, rather than failing during the <code>Read</code> function, which takes considerably longer.</li> <li>Default values can be implied for fields, rather than requiring an explicit <code>d.Set</code> in the Read function for every field - this allows us to ensure that an empty value/list is set for a field, rather than being <code>null</code> and thus unreferenceable in user configs.</li> </ol> </li> <li>Using the Typed SDK allows Data Sources and Resources to (in the future) be migrated across to using <code>hashicorp/terraform-plugin-framework</code> rather than <code>hashicorp/terraform-plugin-sdk</code> without rewriting the resource - which will unlock a number of benefits to end-users, but does involve some configuration changes (and as such will need to be done in a major release).</li> <li>Using the Typed SDK means that these Data Sources/Resources can be more easily swapped out for generated versions down the line (since the code changes will be far smaller).</li> </ul> <p>To facilitate the migration across to Typed Resources, we ask that any new Data Source or Resource which is added to the Provider is added as a Typed Data Source/Resource. Enhancements to existing Data Sources/Resources which are Untyped Resources can remain as Untyped Resources, however these will need to be migrated across in the future.</p> <pre><code>package someservice\n\nimport ...\n\nfunc someResource() *pluginsdk.Resource {\nreturn &amp;pluginsdk.Resource{\nCreate: someResourceCreate,\nRead:   someResourceRead,\nUpdate: someResourceUpdate,\nDelete: someResourceDelete,\n\nImporter: pluginsdk.ImporterValidatingResourceId(func(id string) error {\n_, err := someresource.ParseSomeResourceID(id)\nreturn err\n}),\n\nTimeouts: &amp;pluginsdk.ResourceTimeout{\nCreate: pluginsdk.DefaultTimeout(30 * time.Minute),\nRead:   pluginsdk.DefaultTimeout(5 * time.Minute),\nUpdate: pluginsdk.DefaultTimeout(30 * time.Minute),\nDelete: pluginsdk.DefaultTimeout(30 * time.Minute),\n},\n\nSchema: map[string]*pluginsdk.Schema{\n// schema fields are defined here\n},\n}\n}\n\nfunc someResourceCreate(d *pluginsdk.ResourceData, meta interface{}) error {\n// create logic is defined here\n}\n\nfunc someResourceUpdate(d *pluginsdk.ResourceData, meta interface{}) error {\n// update logic is defined here\n}\n\nfunc someResourceRead(d *pluginsdk.ResourceData, meta interface{}) error {\n// read logic is defined here\n}\n\nfunc someResourceDelete(d *pluginsdk.ResourceData, meta interface{}) error {\n// delete logic is defined here\n}\n</code></pre> <p>Typed resources are initialised using interfaces and methods from the <code>sdk</code> package within the provider and will look something like the example below:</p> <pre><code>package someservice\n\nimport ...\n\ntype SomeResource struct{}\n\nvar (\n_ sdk.Resource           = SomeResource{}\n_ sdk.ResourceWithUpdate = SomeResource{}\n)\n\ntype SomeResourceModel struct {\nDisplayName           string            `tfschema:\"display_name\"`\nResourceGroup         string            `tfschema:\"resource_group_name\"`\nSku                   string            `tfschema:\"sku_name\"`\nTags                  map[string]string `tfschema:\"tags\"`\nTenantId              string            `tfschema:\"tenant_id\"`\n}\n\nfunc (r SomeResource) ResourceType() string {\nreturn \"azurerm_some_resource\"\n}\n\nfunc (r SomeResource) ModelObject() interface{} {\nreturn &amp;SomeResourceModel{}\n}\n\nfunc (r SomeResource) IDValidationFunc() pluginsdk.SchemaValidateFunc {\nreturn someService.ValidateSomeResourceID\n}\n\nfunc (r SomeResource) Arguments() map[string]*pluginsdk.Schema {\nreturn map[string]*pluginsdk.Schema{\n// settable schema fields are set here\n}\n}\n\nfunc (r SomeResource) Attributes() map[string]*pluginsdk.Schema {\nreturn map[string]*pluginsdk.Schema{\n// read-only schema fields are set here\n}\n}\n\nfunc (r SomeResource) Create() sdk.ResourceFunc {\nreturn sdk.ResourceFunc{\nTimeout: 30 * time.Minute,\nFunc:    func(ctx context.Context, metadata sdk.ResourceMetaData) error {\n// create logic is defined here \n},\n}\n}\n\nfunc (r SomeResource) Update() sdk.ResourceFunc {\nreturn sdk.ResourceFunc{\nTimeout: 30 * time.Minute,\nFunc:    func(ctx context.Context, metadata sdk.ResourceMetaData) error {\n// update logic is defined here\n},\n}\n}\n\nfunc (r SomeResource) Read() sdk.ResourceFunc {\nreturn sdk.ResourceFunc{\nTimeout: 5 * time.Minute,\nFunc:    func(ctx context.Context, metadata sdk.ResourceMetaData) error {\n// read logic is defined here\n},\n}\n}\n\nfunc (r SomeResource) Delete() sdk.ResourceFunc {\nreturn sdk.ResourceFunc{\nTimeout: 5 * time.Minute,\nFunc:    func(ctx context.Context, metadata sdk.ResourceMetaData) error {\n// delete logic is defined here\n},\n}\n}\n</code></pre>"},{"location":"topics/best-practices/#setting-properties-to-optional-computed","title":"Setting Properties to Optional + Computed","text":"<p>There's a number of API's within Azure which will specify a default value for a field if one isn't specified, for example the createMode field is typically defaulted (server-side) to Default.</p> <p>The Azure Provider currently makes use of <code>hashicorp/terraform-plugin-sdk@v2</code> to define Data Sources and Resources, which under the hood uses v5 of the Terraform Protocol to interact with Terraform Core.</p> <p>In version 5 of the Terraform Protocol, if a field is created with one value at Create time and returns a different value immediately after creation, then an internal warning is logged (but no error is raised) - meaning that the only way this change is visible is through a diff when terraform plan is run. The next version of the Terraform Protocol (v6 - used by <code>hashicorp/terraform-plugin-framework</code>) changes this from a logged warning to an error at runtime - meaning that these diff's will become more visible to users (and need to be accounted for in the provider).</p> <p>To workaround situations where we need to expose the default value from the Azure API - we've historically marked fields as both Optional and Computed - meaning that a value will be returned from the API when it's not defined.</p> <p>Whilst this works, one side-effect is that it's hard for users to reset a field to it's default value when this is done - as such some fields today (such as the subnets block within the azurerm_virtual_network resource) require that an explicit empty value is specified (for example subnets = []) to remove this value, where this field is Optional &amp; Computed.</p> <p>In order to solve this, (new) fields should no longer be marked as <code>Optional</code> + <code>Computed</code> - instead where a split Create and Update method is used (see above) users can lean on <code>ignore_changes</code> to ignore values from a field with a default value, should they wish to continue using the default value.</p> <p>This approach means that we can support users who want to use the default value (by specifying ignore_changes = [\"some_field\"]), users who want to explicitly define this value (e.g. some_field = \"bar\") and users who need to remove this value (by either omitting the field or defining it as null, so that gets removed).</p> <p>Over time, the existing resources will be migrated from <code>Optional</code> + <code>Computed</code> -&gt; <code>Optional</code> (allowing users to rely on ignore_changes) so that this becomes more behaviourally consistent - however new fields should be defined as <code>Optional</code> alone, rather than <code>Optional</code> and <code>Computed</code>.</p>"},{"location":"topics/building-the-provider/","title":"Building the Provider","text":"<p>See DEVELOPER.md.</p>"},{"location":"topics/debugging-the-provider/","title":"Debugging the Provider","text":"<p>The provider can be debugged in a number of ways:</p> <ul> <li>Adding Log Messages</li> <li>Proxying Traffic</li> <li>Attaching a Debugger</li> </ul>"},{"location":"topics/debugging-the-provider/#logs","title":"Logs","text":"<p>Adding logging is the most basic, and simplest of ways to debug the provider. Log messages can be added with logging statements such as:</p> <pre><code>// info message\nid, err := parse.SomeResourceId(d.Id())\nif err != nil {\nreturn err\n}\nlog.Printf(\"[INFO] %s was not found - removing from state\", *id)\n\n// debug message\nlog.Printf(\"[DEBUG] Importing Resource - parsing %q\", d.Id())\n</code></pre> <p>Note: When logging, lean on the Resource ID Struct (returned from the Parse method above - as shown in the 'info' example above) rather than outputting the Raw Resource ID value (as shown in the debug example above)</p> <p>These can be viewed by running Terraform (or the Acceptance Test) with logging enabled:</p> <pre><code>$ TF_LOG=INFO terraform apply\n$ TF_LOG=DEBUG make acctests SERVICE='&lt;service&gt;' TESTARGS='-run=&lt;nameOfTheTest&gt;' TESTTIMEOUT='60m'\n</code></pre> <p>For more information see the official Terraform plugin logging documentation.</p>"},{"location":"topics/debugging-the-provider/#proxy","title":"Proxy","text":"<p>A useful step between logging and actual debugging is proxying the traffic through a web debugging proxy such as Charles Proxy (macOS) or Fiddler (Windows). These allow inspection of the web traffic between the provider and Azure to confirm what is actually going across the wire.</p> <p>You will need to enable HTTPS proxy support (usually by adding a certificate to your system) and then assuming the proxy is running on port <code>8888</code>:</p> <pre><code>$ http_proxy=http://localhost:8888 https_proxy=http://localhost:8888 terraform apply\n$ http_proxy=http://localhost:8888 https_proxy=http://localhost:8888 make acctests SERVICE='&lt;service&gt;' TESTARGS='-run=&lt;nameOfTheTest&gt;' TESTTIMEOUT='60m' </code></pre>"},{"location":"topics/debugging-the-provider/#debugger-delve","title":"Debugger (delve)","text":"<p>And finally the most advanced and powerful debugging tool is attaching a debugger such as delve to the provider whilst it is running.</p> <p>We generally recommend using Goland as it provides (amongst other features) native integrations for debugging - see OpenCredo's blog post for an example - however it's also possible to use VSCode and the delve CLI - configuring these is outside of the scope of this project.</p>"},{"location":"topics/frequently-asked-questions/","title":"Frequently Asked Questions","text":"<p>Note: This is a work-in-progress and will be extended over time.</p>"},{"location":"topics/frequently-asked-questions/#how-can-i-help","title":"How can I help?","text":"<p>Great question, we assign labels to each GitHub issue to try and group them, a number of these are relevant for users looking to contribute:</p> <ul> <li><code>good-first-issue</code> - this label is used to indicate that we think this would make a good issue for users looking to start contributing to the Provider. These are generally small enhancements, such as adding a new field to an existing resource - or documentation changes - and where we're adding this (in more recent issues) we're trying to provide a little context in one of the comments.</li> <li><code>help-wanted</code> - we use this to highlight enhancement issues that are possible and will have a great impact, but that the maintainers are unlikely to reach in the near future.</li> </ul> <p>The Contributor Readme contains guides on the most common contribution types we see, but if you have any questions not answered in this documentation, please reach out (either in our community slack, or by opening an issue - details can be found in the contributor readme).</p>"},{"location":"topics/frequently-asked-questions/#how-often-is-the-provider-released","title":"How often is the Provider released?","text":"<p>The estimated dates for each release of the Provider can be found on the Milestones page.</p> <p>As a general rule the Provider is typically released weekly on a Thursday, however this can vary (for example during the winter holidays), as such we recommend checking the Milestones page for the most up to date information.</p>"},{"location":"topics/frequently-asked-questions/#my-pull-request-has-merge-conflicts-should-i-rebasemerge-from-the-main-branch","title":"My Pull Request has merge conflicts, should I rebase/merge from the <code>main</code> branch?","text":"<p>Whilst we do our best to review pull requests as they come in, unfortunately there are cases where it can take some time and merge conflicts can result if they have been sitting for a while. Generally speaking we recommend rebasing/merging from <code>main</code> only once a maintainer has taken a look through the PR and explicitly requested it.  </p> <p>TODO.</p>"},{"location":"topics/frequently-asked-questions/#once-a-major-release-is-published-will-new-features-and-fixes-be-backported-to-previous-versions","title":"Once a major release is published, will new features and fixes be backported to previous versions?","text":"<p>Generally new features and fixes will only be added to the most recent major version.</p> <p>Due to the high touch nature of provider development and the extensive regression testing required to ensure stability, maintaining multiple versions of the provider is not sustainable at this time. An exception to this could be a discovered security vulnerability for which backporting may be the most reasonable course of action. These will be reviewed on a case by case basis.</p>"},{"location":"topics/frequently-asked-questions/#what-do-the-different-github-labels-mean","title":"What do the different GitHub labels mean?","text":"<p>As a general rule the different Azure Services are represented as <code>service/{serviceName}</code> - for other labels we're working through adding descriptions which can be found on the GitHub Labels page for this repository.</p>"},{"location":"topics/frequently-asked-questions/#why-was-my-comment-marked-as-off-topic","title":"Why was my comment marked as off-topic?","text":"<p>Whilst we thank you for your feedback, we mark comments along the lines of \"me too\" / \"when will this be fixed?\" (or generally off-topic comments) as off-topic so that they're hidden by default.</p> <p>As this repository has a large/active community, we instead ask that you use a thumbs-up GitHub reaction to the original issue so that we can prioritise this work without notifying everybody subscribed to the repository.</p> <p>We appreciate this may be frustrating to have a comment marked as off-topic - when we've not done this we've noticed a number of users regularly adding \"+1\" / \"me too\" comments, which ends up causing more distractions for both the maintainers and community in general.</p>"},{"location":"topics/frequently-asked-questions/#why-did-you-close-my-question","title":"Why did you close my question?","text":"<p>Whilst we thank you for reaching out, unfortunately we're unable to assist with individual usage questions related to the Azure Provider.</p> <p>We've closed your issue because we believe it's an issue with the Terraform Configuration being used (or, that the credentials being used to interact with Azure may not have permission to the resources in question), rather than a bug in the Azure Provider.</p> <p>We instead ask that configuration issues/usage questions related to the Provider are opened on the Community Discuss forum so that we can keep this repository focused on bugs/feature enhancements related to the Azure Provider.</p>"},{"location":"topics/guide-new-data-source/","title":"Guide: New Data Source","text":"<p>This guide covers adding a new Data Source to a Service Package, see adding a New Service Package if the Service Package doesn't exist yet.</p>"},{"location":"topics/guide-new-data-source/#related-topics","title":"Related Topics","text":"<ul> <li>Acceptance Testing</li> <li>Our Recommendations for opening a Pull Request</li> </ul>"},{"location":"topics/guide-new-data-source/#stages","title":"Stages","text":"<p>At this point in time the AzureRM Provider supports both Typed and Untyped Data Sources - more information can be found in the High Level Overview.</p> <p>This guide covers adding a new Typed Data Source, which makes use of the Typed SDK within this repository and requires the following steps:</p> <ol> <li>Ensure all the dependencies are installed (see Building the Provider).</li> <li>Add an SDK Client (if required).</li> <li>Define the Resource ID.</li> <li>Scaffold an empty/new Data Source.</li> <li>Register the new Data Source.</li> <li>Add Acceptance Test(s) for this Data Source.</li> <li>Run the Acceptance Test(s).</li> <li>Add Documentation for this Data Source.</li> <li>Send the Pull Request.</li> </ol> <p>We'll go through each of those steps in turn, presuming that we're creating a Data Source for a Resource Group.</p>"},{"location":"topics/guide-new-data-source/#step-1-ensure-the-tools-are-installed","title":"Step 1: Ensure the Tools are installed","text":"<p>See Building the Provider.</p>"},{"location":"topics/guide-new-data-source/#step-2-add-an-sdk-client-if-required","title":"Step 2: Add an SDK Client (if required)","text":"<p>If you're creating a new Data Source for a Resource that's already created by Terraform, the SDK Client you need to use is likely already supported (and so you can skip this section).</p> <p>However if the SDK Client you need to use isn't already configured in the Provider, we'll cover how to add and configure the SDK Client.</p> <p>Determining which SDK Client you should be using is a little complicated unfortunately, in this case the SDK Client we want to use is: <code>github.com/Azure/azure-sdk-for-go/services/resources/mgmt/2020-06-01/resources</code>.</p> <p>The Client for the Service Package can be found in <code>./internal/services/{name}/client/client.go</code> - and we can add an instance of the SDK Client we want to use (here <code>resources.GroupsClient</code>) and configure it (adding credentials etc): </p> <pre><code>package client\n\nimport (\n\"github.com/Azure/azure-sdk-for-go/services/resources/mgmt/2020-06-01/resources\" // nolint: staticcheck\n\"github.com/hashicorp/terraform-provider-azurerm/internal/common\"\n)\n\ntype Client struct {\nGroupsClient *resources.GroupsClient\n}\n\nfunc NewClient(o *common.ClientOptions) *Client {\ngroupsClient := resources.NewGroupsClientWithBaseURI(o.ResourceManagerEndpoint, o.SubscriptionId)\no.ConfigureClient(&amp;groupsClient.Client, o.ResourceManagerAuthorizer)\n\n// ...\n\nreturn &amp;Client{\nGroupsClient: &amp;groupsClient,\n}\n}\n</code></pre> <p>A few things of note here:</p> <ol> <li>The field <code>GroupsClient</code> within the struct is a pointer, meaning that if it's not initialized the Provider will crash/panic - which is intentional to avoid using an unconfigured client (which will have no credentials, and cause misleading errors).</li> <li>When creating the client, note that we're using <code>NewGroupsClientWithBaseURI</code> (and not <code>NewGroupsClient</code>) from the SDK - this is intentional since we want to specify the Resource Manager endpoint for the Azure Environment (e.g. Public, China, US Government etc) that the credentials we're using are connected to.</li> <li>The call to <code>o.ConfigureClient</code> configures the authorization token which should be used for this SDK Client - in most cases <code>ResourceManagerAuthorizer</code> is the authorizer you want to use.</li> </ol> <p>At this point, this SDK Client should be usable within the Data Sources via:</p> <pre><code>client := metadata.Client.{ServicePackage}.{ClientField}\n</code></pre> <p>For example, in this case:</p> <pre><code>client := metadata.Client.Resource.GroupsClient\n</code></pre>"},{"location":"topics/guide-new-data-source/#step-3-define-the-resource-id","title":"Step 3: Define the Resource ID","text":"<p>Next we're going to generate a Resource ID Struct, Parser and Validator for the specific Azure Resource that we're working with, in this case for a Resource Group.</p> <p>We have some automation within the codebase which generates all of that using <code>go:generate</code> commands - what this means is that we can add a single line to the <code>resourceids.go</code> file within the Service Package (in this case <code>./internal/services/resources/resourceids.go</code>) to generate these.</p> <p>An example of this is shown below:</p> <pre><code>package resource\n\n//go:generate go run ../../tools/generator-resource-id/main.go -path=./ -name=ResourceGroupExample -id=/subscriptions/12345678-1234-9876-4563-123456789012/resourceGroups/group1\n</code></pre> <p>In this case, you need to specify the <code>name</code> the Resource (in this case <code>ResourceGroupExample</code>) and the <code>id</code> which is an example of this Resource ID (in this case <code>/subscriptions/12345678-1234-9876-4563-123456789012/resourceGroups/group1</code>).</p> <p>The segments of the Resource ID should be camelCased (e.g. <code>resourceGroups</code> rather than <code>resourcegroups</code>) per the Azure API Specification - see Azure Resource IDs in the Glossary for more information.</p> <p>You can generate the Resource ID Struct, Parser and Validation functions by running <code>make generate</code> - which will output the following files:</p> <ul> <li><code>./internal/service/resource/parse/resource_group_example.go</code> - contains the Resource ID Struct, Formatter and Parser.</li> <li><code>./internal/service/resource/parse/resource_group_example_test.go</code> - contains tests for those ^.</li> <li><code>./internal/service/resource/validate/resource_group_example_id.go</code> - contains Terraform validation functions for the Resource ID.</li> </ul> <p>These types can then be used in the Data Source we're creating below.</p>"},{"location":"topics/guide-new-data-source/#step-4-scaffold-an-emptynew-data-source","title":"Step 4: Scaffold an empty/new Data Source","text":"<p>Since we're creating a Data Source for a Resource Group, which is a part of the Resources API - we'll want to create an empty Go file within the Service Package for Resources, which is located at <code>./internal/services/resources</code>.</p> <p>In this case, this would be a file called <code>resource_group_example_data_source.go</code>, which we'll start out with the following:</p> <p>Note: We'd normally name this file <code>resource_group_data_source.go</code> - but there's an existing Data Source for Resource Groups, so we're appending <code>example</code> to the name throughout this guide. </p> <pre><code>package resources\n\nimport \"github.com/hashicorp/terraform-provider-azurerm/internal/sdk\"\n\nvar _ sdk.DataSource = ResourceGroupExampleDataSource{}\n\ntype ResourceGroupExampleDataSource struct {}\n</code></pre> <p>Note: Your editor may show a suggestion to implement the methods defined in <code>sdk.DataSource</code> for the <code>ResourceGroupExampleDataSource</code> struct - we'd recommend holding off the first time around to explain each of the methods.</p> <p>In this case the interface <code>sdk.DataSource</code> defines all of the methods required for a Data Source which the newly created struct for the Resource Group Data Source need to implement, which are:</p> <pre><code>type DataSource interface {\nArguments() map[string]*schema.Schema\nAttributes() map[string]*schema.Schema\nModelObject() interface{}\nResourceType() string\nRead() ResourceFunc\n}\n</code></pre> <p>To go through these in turn:</p> <ul> <li><code>Arguments</code> returns a list of schema fields which are user-specifiable - either Required or Optional.</li> <li><code>Attributes</code> returns a list of schema fields which are Computed (read-only).</li> <li><code>ModelObject</code> returns a reference to a Go struct which is used as the Model for this Data Source (this can also return <code>nil</code> if there's no model).</li> <li><code>ResourceType</code> returns the name of this resource within the Provider (for example <code>azurerm_resource_group_example</code>).</li> <li><code>Read</code> returns a function defining both the Timeout and the Read function (which retrieves information from the Azure API) for this Data Source.</li> </ul> <pre><code>func (ResourceGroupExampleDataSource) Arguments() map[string]*pluginsdk.Schema {\nreturn map[string]*pluginsdk.Schema{\n\"name\": {\nType:     pluginsdk.TypeString,\nRequired: true,\n},\n}\n}\n\nfunc (ResourceGroupExampleDataSource) Attributes() map[string]*pluginsdk.Schema {\nreturn map[string]*pluginsdk.Schema{\n\"location\": {\nType:      pluginsdk.TypeString,\nComputed:  true,\n},\n\n\"tags\": commonschema.TagsDataSource(),\n}\n}\n\nfunc (ResourceGroupExampleDataSource) ModelObject() interface{} {\nreturn nil\n}\n\nfunc (ResourceGroupExampleDataSource) ResourceType() string {\nreturn \"azurerm_resource_group_example\"\n}\n</code></pre> <p>In this case we're using the resource type <code>azurerm_resource_group_example</code> as an existing Data Source for <code>azurerm_resource_group</code> exists and the names need to be unique.</p> <p>These functions define a Data Source called <code>azurerm_resource_group_example</code>, which has one Required argument called <code>name</code> and two Computed arguments called <code>location</code> and <code>tags</code>. We'll come back to <code>ModelObject</code> later.</p> <p>Next up, let's implement the Read function - which retrieves the information about the Resource Group from Azure:</p> <pre><code>func (ResourceGroupExampleDataSource) Read() sdk.ResourceFunc {\nreturn sdk.ResourceFunc{\n\n// the Timeout is how long Terraform should wait for this function to run before returning an error\n// whilst 5 minutes may initially seem excessive, we set this as a default to account for rate\n// limiting - but having this here means that users can override this in their config as necessary\nTimeout: 5 * time.Minute,\n\n// the Func returns a function which retrieves the current state of the Resource Group into the state \nFunc: func(ctx context.Context, metadata sdk.ResourceMetaData) error {\nclient := metadata.Client.Resource.GroupsClient\n\n// retrieve the Name for this Resource Group from the Terraform Config\n// and then create a Resource ID for this Resource Group\n// using the Subscription ID &amp; name\nsubscriptionId := metadata.Client.Account.SubscriptionId\nname := metadata.ResourceData.Get(\"name\").(string)\nid := parse.NewResourceGroupExampleID(subscriptionId, name)\n\n// then retrieve the Resource Group by it's Name\nresp, err := client.Get(ctx, name)\nif err != nil {\n// if the Resource Group doesn't exist (e.g. we get a 404 Not Found)\n// since this is a Data Source we must return an error if it's Not Found\nif utils.ResponseWasNotFound(read.Response) {\nreturn fmt.Errorf(\"%s was not found\", id)\n}\n\n// otherwise it's a genuine error (auth/api error etc) so raise it\n// there should be enough context for the user to interpret the error\n// or raise a bug report if there's something we should handle\nreturn fmt.Errorf(\"retrieving %s: %+v\", id, err)\n}\n\n// now we know the Resource Group exists, set the Resource ID for this Data Source\n// this means that Terraform will track this as existing\nmetadata.SetID(id)\n\n// at this point we can set information about this Resource Group into the State\n// whilst traditionally we would do this via `metadata.ResourceData.Set(\"foo\", \"somevalue\")\n// the Location and Tags fields are a little different - and we have a couple of normalization\n// functions for these.\n\n// whilst this may seem like a weird thing to call out in an example, because these two fields\n// are present on the majority of resources, we hope it explains why they're a little different\n\n// in this case the Location can be returned in various different forms, for example\n// \"West Europe\", \"WestEurope\" or \"westeurope\" - as such we normalize these into a\n// lower-cased singular word with no spaces (e.g. \"westeurope\") so this is consistent\n// for users\nmetadata.ResourceData.Set(\"location\", location.NormalizeNilable(resp.Location))\n\n// (as above) Tags are a little different, so we have a dedicated helper function\n// to flatten these consistently across the Provider\nreturn tags.FlattenAndSet(metadata.ResourceData, resp.Tags)\n},\n}\n}\n</code></pre> <p>At this point the finished Data Source should look like (including imports):</p> <pre><code>package resource\n\nimport (\n\"context\"\n\"fmt\"\n\"time\"\n\n\"github.com/hashicorp/go-azure-helpers/resourcemanager/commonschema\"\n\"github.com/hashicorp/go-azure-helpers/resourcemanager/location\"\n\"github.com/hashicorp/terraform-provider-azurerm/internal/sdk\"\n\"github.com/hashicorp/terraform-provider-azurerm/internal/services/appservice/parse\"\n\"github.com/hashicorp/terraform-provider-azurerm/internal/tags\"\n\"github.com/hashicorp/terraform-provider-azurerm/internal/tf/pluginsdk\"\n\"github.com/hashicorp/terraform-provider-azurerm/utils\"\n)\n\ntype ResourceGroupExampleDataSource struct{}\n\nfunc (d ResourceGroupExampleDataSource) Arguments() map[string]*pluginsdk.Schema {\nreturn map[string]*pluginsdk.Schema{\n\"name\": {\nType:     pluginsdk.TypeString,\nRequired: true,\n},\n}\n}\n\nfunc (d ResourceGroupExampleDataSource) Attributes() map[string]*pluginsdk.Schema {\nreturn map[string]*pluginsdk.Schema{\n\"location\": {\nType:     pluginsdk.TypeString,\nComputed: true,\n},\n\n\"tags\": commonschema.TagsDataSource(),\n}\n}\n\nfunc (d ResourceGroupExampleDataSource) ModelObject() interface{} {\nreturn nil\n}\n\nfunc (d ResourceGroupExampleDataSource) ResourceType() string {\nreturn \"azurerm_resource_group_example\"\n}\n\nfunc (d ResourceGroupExampleDataSource) Read() sdk.ResourceFunc {\nreturn sdk.ResourceFunc{\n\n// the Timeout is how long Terraform should wait for this function to run before returning an error\n// whilst 5 minutes may initially seem excessive, we set this as a default to account for rate\n// limiting - but having this here means that users can override this in their config as necessary\nTimeout: 5 * time.Minute,\n\n// the Func here is the\nFunc: func(ctx context.Context, metadata sdk.ResourceMetaData) error {\nclient := metadata.Client.Resource.GroupsClient\n\n// retrieve the Name for this Resource Group from the Terraform Config\n// and then create a Resource ID for this Resource Group\n// using the Subscription ID &amp; name\nsubscriptionId := metadata.Client.Account.SubscriptionId\nname := metadata.ResourceData.Get(\"name\").(string)\nid := parse.NewResourceGroupExampleID(subscriptionId, name)\n\n// then retrieve the Resource Group by it's Name\nresp, err := client.Get(ctx, name)\nif err != nil {\n\n// if the Resource Group doesn't exist (e.g. we get a 404 Not Found)\n// since this is a Data Source we must return an error if it's Not Found\nif utils.ResponseWasNotFound(read.Response) {\nreturn fmt.Errorf(\"%s was not found\", id)\n}\n\n// otherwise it's a genuine error (auth/api error etc) so raise it\n// there should be enough context for the user to interpret the error\n// or raise a bug report if there's something we should handle\nreturn fmt.Errorf(\"retrieving %s: %+v\", id, err)\n}\n\n// now we know the Resource Group exists, set the Resource ID for this Data Source\n// this means that Terraform will track this as existing\nmetadata.SetID(id)\n\n// at this point we can set information about this Resource Group into the State\n// whilst traditionally we would do this via `metadata.ResourceData.Set(\"foo\", \"somevalue\")\n// the Location and Tags fields are a little different - and we have a couple of normalization\n// functions for these.\n\n// whilst this may seem like a weird thing to call out in an example, because these two fields\n// are present on the majority of resources, we hope it explains why they're a little different\n\n// in this case the Location can be returned in various different forms, for example\n// \"West Europe\", \"WestEurope\" or \"westeurope\" - as such we normalize these into a\n// lower-cased singular word with no spaces (e.g. \"westeurope\") so this is consistent\n// for users\nmetadata.ResourceData.Set(\"location\", location.NormalizeNilable(resp.Location))\n\nreturn tags.FlattenAndSet(metadata.ResourceData, resp.Tags)\n},\n}\n}\n</code></pre> <p>At this point in time this Data Source is now code-complete - there's an optional extension to make this cleaner by using a Typed Model, however this isn't necessary.</p>"},{"location":"topics/guide-new-data-source/#step-5-register-the-new-data-source","title":"Step 5: Register the new Data Source","text":"<p>Data Sources are registered within the <code>registration.go</code> within each Service Package - and should look something like this:</p> <pre><code>package resource\n\nimport \"github.com/hashicorp/terraform-provider-azurerm/internal/sdk\"\n\nvar _ sdk.TypedServiceRegistration = Registration{}\n\ntype Registration struct{}\n\n// ...\n\n// DataSources returns a list of Data Sources supported by this Service\nfunc (Registration) DataSources() []sdk.DataSource {\nreturn []sdk.DataSource{}\n}\n</code></pre> <p>Note: It's possible that the Service Registration (above) doesn't currently support Typed Resources, in which case you may need to add the following:</p> <pre><code>var _ sdk.TypedServiceRegistration = Registration{}\n\ntype Registration struct {\n}\n\nfunc (Registration) Name() string {\nreturn \"Some Service\"\n}\n\nfunc (Registration) DataSources() []sdk.DataSource {\nreturn []sdk.DataSource{}\n}\n\nfunc (Registration) Resources() []sdk.Resource {\nreturn []sdk.Resource{}\n}\n\nfunc (Registration) WebsiteCategories() []string {\nreturn []string{\n\"Some Service\",\n}\n}\n</code></pre> <p>In this case you'll also need to add a line to register this Service Registration in the list of Typed Service Registrations.</p> <p>To register the Data Source we need to add an instance of the struct used for the Data Source to the list of Data Sources, for example:</p> <pre><code>// DataSources returns a list of Data Sources supported by this Service\nfunc (Registration) DataSources() []sdk.DataSource {\nreturn []sdk.DataSource{\nResourceGroupExampleDataSource{},   }\n}\n</code></pre> <p>At this point the Data Source is registered, as when the Azure Provider builds up a list of supported Data Sources during initialization, it parses each of the Service Registrations to put together a definitive list of the Data Sources that we support.</p> <p>This means that if you Build the Provider, at this point you should be able to apply the following Data Source:</p> <pre><code>provider \"azurerm\" {\n  features {}\n}\n\ndata \"azurerm_resource_group_example\" \"test\" {\n  name = \"some-pre-existing-resource-group\" # presuming this resource group exists ;)\n}\n\noutput \"location\" {\n  value = data.azurerm_resource_group_example.test.location\n}\n</code></pre>"},{"location":"topics/guide-new-data-source/#step-6-add-acceptance-tests-for-this-data-source","title":"Step 6: Add Acceptance Test(s) for this Data Source","text":"<p>We're going to test the Data Source that we've just built by dynamically provisioning a Resource Group using the Azure Provider, then asserting that we can look up that Resource Group using the new <code>azurerm_resource_group_example</code> Data Source.</p> <p>In Go tests are expected to be in a file name in the format <code>{original_file_name}_test.go</code> - in our case that'd be <code>resource_group_example_data_source_test.go</code>, into which we'll want to add: </p> <pre><code>package resource_test\n\nimport (\n\"fmt\"\n\"testing\"\n\n\"github.com/hashicorp/go-azure-helpers/resourcemanager/location\"\n\"github.com/hashicorp/terraform-provider-azurerm/internal/acceptance\"\n\"github.com/hashicorp/terraform-provider-azurerm/internal/acceptance/check\"\n)\n\ntype ResourceGroupExampleDataSource struct{}\n\nfunc TestAccResourceGroupExampleDataSource_basic(t *testing.T) {\ndata := acceptance.BuildTestData(t, \"data.azurerm_resource_group_example\", \"test\")\nr := ResourceGroupExampleDataSource{}\n\ndata.DataSourceTest(t, []acceptance.TestStep{\n{\nConfig: r.basic(data),\nCheck: acceptance.ComposeTestCheckFunc(\ncheck.That(data.ResourceName).Key(\"location\").HasValue(location.Normalize(data.Locations.Primary)),\ncheck.That(data.ResourceName).Key(\"tags.%\").HasValue(\"1\"),\ncheck.That(data.ResourceName).Key(\"tags.env\").HasValue(\"test\"),\n),\n},\n})\n}\n\nfunc (ResourceGroupExampleDataSource) basic(data acceptance.TestData) string {\nreturn fmt.Sprintf(`\nprovider \"azurerm\" {\n  features {}\n}\n\nresource \"azurerm_resource_group\" \"test\" {\n  name     = \"acctestRg-%d\"\n  location = \"%s\"\n\n  tags = {\n    env = \"test\"\n  }\n}\n\ndata \"azurerm_resource_group_example\" \"test\" {\n  name = azurerm_resource_group.test.name\n}\n`, data.RandomInteger, data.Locations.Primary)\n}\n</code></pre> <p>There's a more detailed breakdown of how this works in the Acceptance Testing reference - but to summarize what's going on here:</p> <ol> <li>Test Terraform Configurations are defined as methods on the struct <code>ResourceGroupExampleDataSource</code> so that they're easily accessible (this helps to avoid them being unintentionally used in other resources).</li> <li>The <code>acceptance.TestData</code> object contains a number of helpers, including both random integers, strings and the Azure Locations where resources should be provisioned - which are used to ensure when tests are run in parallel that we provision unique resources for testing purposes.</li> <li>We're asserting on the Computed (e.g. read-only) fields returned from the Resource - we don't check the user-specified fields (<code>name</code> in this case) as if it's missing, the test will fail to find the Resource Group.</li> <li>We append <code>_test</code> to the Go package name (e.g. <code>resource_test</code>) since we need to be able to access both the <code>resource</code> package and the <code>acceptance</code> package (which is a circular reference, otherwise).</li> </ol> <p>At this point we should be able to run this test.</p>"},{"location":"topics/guide-new-data-source/#step-7-run-the-acceptance-tests","title":"Step 7: Run the Acceptance Test(s)","text":"<p>Detailed instructions on Running the Tests can be found in this guide - when a Service Principal is configured you can run the test above using:</p> <pre><code>make acctests SERVICE='resource' TESTARGS='-run=TestAccResourceGroupExampleDataSource_basic' TESTTIMEOUT='60m'\n</code></pre> <p>Which should output:</p> <pre><code>==&gt; Checking that code complies with gofmt requirements...\n==&gt; Checking that Custom Timeouts are used...\n==&gt; Checking that acceptance test packages are used...\nTF_ACC=1 go test -v ./internal/services/resource -run=TestAccResourceGroupExampleDataSource_basic -timeout 60m -ldflags=\"-X=github.com/hashicorp/terraform-provider-azurerm/version.ProviderVersion=acc\"\n=== RUN   TestAccResourceGroupExampleDataSource_basic\n=== PAUSE TestAccResourceGroupExampleDataSource_basic\n=== CONT  TestAccResourceGroupExampleDataSource_basic\n--- PASS: TestAccResourceGroupExampleDataSource_basic (88.15s)\nPASS\nok      github.com/hashicorp/terraform-provider-azurerm/internal/services/resource  88.735s\n</code></pre>"},{"location":"topics/guide-new-data-source/#step-8-add-documentation-for-this-data-source","title":"Step 8: Add Documentation for this Data Source","text":"<p>At this point in time documentation for each Data Source (and Resource) is written manually, located within the <code>./website</code> folder - in this case this will be located at <code>./website/docs/d/resource_group_example.html.markdown</code>.</p> <p>There is a tool within the repository to help scaffold the documentation for a Data Source - the documentation for this Data Source can be scaffolded via the following command:</p> <pre><code>$ make scaffold-website BRAND_NAME=\"Resource Group Example\" RESOURCE_NAME=\"azurerm_resource_group_example\" RESOURCE_TYPE=\"data\"\n</code></pre> <p>The documentation should look something like below - containing both an example usage and the required, optional and computed fields:</p> <p>Note: In the example below you'll need to replace each <code>[]</code> with a backtick \"`\" - as otherwise this gets rendered incorrectly, unfortunately.</p> <pre><code>---\nsubcategory: \"Base\"\nlayout: \"azurerm\"\npage_title: \"Azure Resource Manager: Data Source: azurerm_resource_group_example\"\ndescription: |-\n  Gets information about an existing Resource Group.\n---\n\n# Data Source: azurerm_resource_group_example\n\nUse this data source to access information about an existing Resource Group.\n\n## Example Usage\n\n[][][]hcl\ndata \"azurerm_resource_group_example\" \"example\" {\n  name = \"existing\"\n}\n\noutput \"id\" {\n  value = data.azurerm_resource_group_example.example.id\n}\n[][][]\n\n## Arguments Reference\n\nThe following arguments are supported:\n\n* `name` - (Required) The Name of this Resource Group.\n\n## Attributes Reference\n\nIn addition to the Arguments listed above - the following Attributes are exported:\n\n* `id` - The ID of the Resource Group.\n\n* `location` - The Azure Region where the Resource Group exists.\n\n* `tags` - A mapping of tags assigned to the Resource Group.\n\n## Timeouts\n\nThe `timeouts` block allows you to specify [timeouts](https://www.terraform.io/language/resources/syntax#operation-timeouts) for certain actions:\n\n* `read` - (Defaults to 5 minutes) Used when retrieving the Resource Group.\n</code></pre> <p>Note: In the example above you'll need to replace each <code>[]</code> with a backtick \"`\" - as otherwise this gets rendered incorrectly, unfortunately.</p>"},{"location":"topics/guide-new-data-source/#step-9-send-the-pull-request","title":"Step 9: Send the Pull Request","text":"<p>See our recommendations for opening a Pull Request.</p>"},{"location":"topics/guide-new-fields-to-data-source/","title":"Guide: Extending a Data Source","text":"<p>It is sometimes necessary to make changes to an existing Data Source. Reasons include:</p> <ul> <li> <p>A new property is added in the referenced resource</p> </li> <li> <p>A property is deprecated and/or no longer available in the referenced resource</p> </li> <li> <p>An API update changes the behaviour of the referenced resource</p> </li> </ul> <p>When updating an existing Data Source keep in mind the configuration of the end user that may be using it.  Mitigations must be taken, where possible, to prevent the change breaking existing user configurations.</p> <p>The process is similar to extending an existing Resource, in that modifications in multiple places are required.</p>"},{"location":"topics/guide-new-fields-to-data-source/#schema","title":"Schema","text":"<p>Building on the example from adding a new data source the new property will need to be added into the <code>Attributes</code> list which contains a list of schema fields that are Computed only.</p> <p>The location of the new property within this list is determined alphabetically. Taking the hypothetical property <code>public_network_access_enabled</code> as an example this would then end up looking like this in <code>Attributes</code>.</p> <pre><code>func (ResourceGroupExampleDataSource) Attributes() map[string]*pluginsdk.Schema {\nreturn map[string]*pluginsdk.Schema{\n\"location\": {\nType:      pluginsdk.TypeString,\nComputed:  true,\n},\n\n\"public_network_access_enabled\": {\nType: pluginsdk.TypeBool,\nComputed: true,\n},       \"tags\": commonschema.TagsDataSource(),\n}\n}\n</code></pre> <ul> <li>For new properties that are ambiguous in their functionality or nature, follow the property naming guidelines when choosing a name.</li> </ul>"},{"location":"topics/guide-new-fields-to-data-source/#read-function","title":"Read function","text":"<ul> <li>The only thing to consider here is setting the new value into state and nil checking beforehand if required.</li> </ul> <pre><code>publicNetworkAccess := true\nif v := props.WorkspaceProperties.PublicNetworkAccess; v != nil {\npublicNetworkAccess = *v\n}\nd.Set(\"public_network_access_enabled\", publicNetworkAccess)\n</code></pre>"},{"location":"topics/guide-new-fields-to-data-source/#tests","title":"Tests","text":"<ul> <li>New properties should be added to the basic data source test with an explicit check.</li> </ul> <pre><code>func TestAccDataSourceSomeResource_basic(t *testing.T) {\ndata := acceptance.BuildTestData(t, \"data.azurerm_some_resource\", \"test\")\nr := AvailabilitySetDataSource{}\n\ndata.DataSourceTest(t, []acceptance.TestStep{\n{\nConfig: r.basic(data),\nCheck: acceptance.ComposeTestCheckFunc(\ncheck.That(data.ResourceName).Key(\"name\").Exists(),\ncheck.That(data.ResourceName).Key(\"resource_group_name\").Exists(),\ncheck.That(data.ResourceName).Key(\"new_property\").HasValue(\"1\"),\n),\n},\n})\n}\n</code></pre>"},{"location":"topics/guide-new-fields-to-data-source/#docs","title":"Docs","text":"<ul> <li>Lastly, don't forget to update the docs where the property ordering is determined alphabetically.</li> </ul>"},{"location":"topics/guide-new-fields-to-resource/","title":"Guide: Extending a Resource","text":"<p>As Azure services evolve and new features or functionalities enter public preview or become GA, their corresponding Terraform resources will need to be extended and/or modified in order to expose newly added functionalities.</p> <p>Oftentimes this involves the addition of a new property or perhaps even the renaming of an existing property.</p>"},{"location":"topics/guide-new-fields-to-resource/#adding-a-new-property","title":"Adding a new property","text":"<p>In order to incorporate a new property into a resource, modifications need to be made in multiple places. These are outlined below with pointers on what to consider and look out for as well as examples.</p>"},{"location":"topics/guide-new-fields-to-resource/#schema","title":"Schema","text":"<p>Building on the example found in adding a new resource the new property will need to be added to either the user configurable list of <code>Arguments</code>, or <code>Attributes</code> if non-configurable.</p> <p>Our hypothetical property <code>public_network_access_enabled</code> will be user configurable and thus will need to be added to the <code>Arguments</code> list.</p> <p>The position of the new property is determined alphabetically and will end up looking like the code block below.</p> <pre><code>func (ResourceGroupExampleResource) Arguments() map[string]*pluginsdk.Schema {\nreturn map[string]*pluginsdk.Schema{\n\"name\": {\nType:     pluginsdk.TypeString,\nRequired: true,\n},\n\n\"location\": commonschema.Location(),\n\n\"public_network_access_enabled\": {\nType: pluginsdk.TypeBool,\nOptional: true,\n}       \"tags\": commonschema.TagsDataSource(),\n}\n}\n</code></pre> <ul> <li> <p>Remember to choose an appropriate name, see our property naming guidelines.</p> </li> <li> <p>Ensure there is appropriate validation, at the very least <code>validation.StringIsNotEmpty</code> should be set for strings where a validation pattern cannot be determined.</p> </li> <li> <p>When adding multiple properties or blocks thought should be given on how to map these, see schema design considerations for specific examples. </p> </li> </ul>"},{"location":"topics/guide-new-fields-to-resource/#create-function","title":"Create function","text":"<ul> <li>The new property needs to be set in the properties struct for the resource.</li> </ul> <pre><code>props := machinelearning.Workspace{\nWorkspaceProperties: &amp;machinelearning.WorkspaceProperties{\nPublicNetworkAccess: utils.Bool(d.Get(\"public_network_access_enabled\").(bool))\n}\n}\n</code></pre>"},{"location":"topics/guide-new-fields-to-resource/#update-function","title":"Update function","text":"<ul> <li>When performing selective updates check whether the property has changed.</li> </ul> <pre><code>if d.HasChange(\"public_network_access_enabled\") {\nprops.WorkspaceProperties.PublicNetworkAccess = utils.Bool(d.Get(\"public_network_access_enabled\").(bool))\n}\n</code></pre>"},{"location":"topics/guide-new-fields-to-resource/#read-function","title":"Read function","text":"<ul> <li> <p>Generally speaking all properties should have a value set into state.</p> </li> <li> <p>If the value returned by the API is a pointer we should nil check this to prevent panics in the provider.</p> </li> </ul> <pre><code>publicNetworkAccess := true\nif v := props.WorkspaceProperties.PublicNetworkAccess; v != nil {\npublicNetworkAccess = *v\n}\nd.Set(\"public_network_access_enabled\", publicNetworkAccess)\n</code></pre>"},{"location":"topics/guide-new-fields-to-resource/#tests","title":"Tests","text":"<ul> <li> <p>It is often sufficient to add a new property to one of the existing, non-basic tests.</p> </li> <li> <p>If the property is <code>Optional</code> then it can be added to the <code>complete</code> test.</p> </li> <li> <p>Properties that are <code>Required</code> will need to be added to all the existing tests for that resource.</p> </li> <li> <p>In cases where a new property or block requires additional setup or pre-requisites it makes sense to create a dedicated test for it.</p> </li> </ul>"},{"location":"topics/guide-new-fields-to-resource/#docs","title":"Docs","text":"<ul> <li> <p>Lastly, don't forget to update the docs with this new property!</p> </li> <li> <p>Property ordering within the docs follows the same conventions as in the Schema.</p> </li> <li> <p><code>Computed</code> only values should be added under <code>Attributes Reference</code></p> </li> </ul>"},{"location":"topics/guide-new-fields-to-resource/#renaming-and-deprecating-a-property","title":"Renaming and Deprecating a Property","text":"<p>Fixing typos in property names or renaming them to improve the meaning is unfortunately not just a matter of updating the name in the resource's code.</p> <p>This is a breaking change and can be done by deprecating the old property, replacing it with a new one, as well as feature flagging its removal in the next major release of the provider.</p> <p>A feature flag is essentially a function that returns a boolean and allows the provider to accommodate alternate behaviours that are meant for major releases. A release feature flag will always return <code>false</code> until it has been hooked up to an environment variable that allows users to toggle the behaviour and can be found in the <code>./internal/features</code> directory.</p> <p>As an example, let's deprecate and replace the property <code>enable_public_network_access</code> with <code>public_network_access_enabled</code>.</p> <pre><code>Schema: map[string]*pluginsdk.Schema{\n...\n\"enable_public_network_access\": {\nType:     pluginsdk.TypeBool,\nOptional: true,\n},\n}\n</code></pre> <p>After deprecation the schema might look like the example below.</p> <pre><code>func resource() *pluginsdk.Resource {\nresource := &amp;pluginsdk.Resource{\n...\nSchema: map[string]*pluginsdk.Schema{\n...\n\n// The deprecated property is moved out of the schema and conditionally added back via the feature flag\n\n\"public_network_access_enabled\": {\nType:       pluginsdk.TypeBool,\nOptional:   true,\nComputed:   !features.FourPointOhBeta()  // Conditionally computed to avoid diffs when both properties are set into state\nConflictsWith: func() []string{          // Conditionally conflict with the deprecated property which will no longer exist in the next major release\nif !features.FourPointOhBeta() {\nreturn []string{\"public_network_access_enabled\"}\n}      return []string{}\n}(),       },\n}\n}\n\nif !features.FourPointOhBeta() {\nresource.Schema[\"enable_public_network_access\"] = &amp;pluginsdk.Schema{\nType:       pluginsdk.TypeBool,\nOptional:   true,\nComputed:   true,\nDeprecated: \"This property has been renamed to `public_network_access_enabled` and will be removed in v4.0 of the provider\",\nConflictsWith: []string{\"public_network_access_enabled\"}\n}   }\n\nreturn resource\n}\n</code></pre> <p>Also make sure to feature flag the behaviour in the create, update and read methods.</p> <pre><code>func create() {\n...\npublicNetworkAccess := false\nif !features.FourPointOhBeta() {\nif v, ok := d.GetOkExists(\"enable_public_network_access\"); ok {\npublicNetworkAccess = v.(bool)\n}       }\n\nif v, ok := d.GetOkExists(\"public_network_access_enabled\"); ok {\npublicNetworkAccess = v.(bool)\n}\n...\n}\n\nfunc read() {\n...\nd.Set(\"public_network_access_enabled\", props.PublicNetworkAccess)\n\nif !features.FourPointOhBeta() {\nd.Set(\"enable_public_network_access\", props.PublicNetworkAccess)\n}   ...\n}\n</code></pre> <p>When deprecating a property in a Typed Resource it is important to ensure that the Go struct representing the schema is correctly tagged to prevent the SDK decoding the removed property when the major version beta / feature flag is in use. In these cases the struct tags must be updated to include <code>,removedInNextMajorVersion</code>.  </p> <pre><code>type ExampleResourceModel struct {\nName                       string `tfschema:\"name\"`\nEnablePublicNetworkAccess  bool   `tfschema:\"enable_public_network_access,removedInNextMajorVersion\"`\nPublicNetworkAccessEnabled bool   `tfschema:\"public_network_access_enabled\"`\n}\n</code></pre>"},{"location":"topics/guide-new-resource-vs-inline/","title":"Guide: When to inline new functionality (as either a block or property) versus a new resource","text":"<p>Sometimes when implementing new functionality it can be a bit unclear whether it is necessary to create a new resource versus to add a new property or block to an existing resource. </p> <p>To get a bit of insight in how a decision can be made, this are some rules of thumb to decide. In case it is unclear, please contact one of the HashiCorp Maintainers.</p>"},{"location":"topics/guide-new-resource-vs-inline/#inline","title":"Inline","text":"<p>Most additional functionality will end up inline an existing resource. </p> <p>APIs to enable or disable functionality, define the resource functionality or configure details on a resource are most of the time inlined. Relations between resources with clearly separate concern (i.e. which VNet a K8s cluster will land in) are most of the time inlined.</p> <p>A few categories of inlined functionality with possible motivations to inline are summed up below.</p>"},{"location":"topics/guide-new-resource-vs-inline/#category-1-properties","title":"Category 1: properties","text":"<ul> <li>When it is 'just a property' of this resource, like <code>sku</code> in the example below.</li> <li>It would require a lot of extra work to make these separate resources.</li> </ul> <pre><code>resource \"azurerm_example_resource\" \"example\" {\n  name = \"ThePerfectExample\"\n  sku  = \"Gold\"\n}\n</code></pre>"},{"location":"topics/guide-new-resource-vs-inline/#category-2-child-resources-which-cannot-be-sparated","title":"Category 2: child resources which cannot be sparated","text":"<ul> <li>It has a strict <code>1:1</code> relation with it's parent resource</li> <li>It cannot be deleted, only returned to a default state (i.e. you might find an API, but only to update the resource)</li> <li>It doesn't have it's own unique Resource ID or name (i.e. <code>&lt;parentId&gt;/default</code> or <code>&lt;parentId&gt;/keyrotationpolicy</code>, not something like <code>&lt;parentId&gt;/subResource/MySubResourceName</code>)</li> <li>It does not have it's own API endpoint but uses the parent resource endpoint</li> <li>It does not cross security/team boundaries in the most common client situation</li> <li>It does not contain backwards compatibility issues</li> </ul>"},{"location":"topics/guide-new-resource-vs-inline/#category-3-relations-between-resources","title":"Category 3: relations between resources","text":"<ul> <li>Resources are really separate and have <code>1:many</code> and <code>many:1</code> relations with a (i.e. a relation property with a resource within a completely different Resource Provider <code>/subscriptions/&lt;subscriptionId&gt;/resourceGroups/&lt;resourceGroup&gt;/providers/Microsoft.Network/networkSecurityGroups/example-nsg</code> and <code>/subscriptions/&lt;subscriptionId&gt;/resourceGroups/&lt;resourceGroup&gt;/providers/Microsoft.Storage/storageAccounts/example-storage</code>: which <code>azurerm_storage_account</code> is used to store the logs from a resource).</li> <li>These relations are created with API calls to the original resource provider, not the connected one</li> <li>Reading the connections between the resources does not require extra permissions than previously necessary to create the resource (i.e. the Service Principal used to read the connection/relation should be also <code>Owner</code>/<code>Contributor</code> on the resource group the connection is made to)</li> </ul>"},{"location":"topics/guide-new-resource-vs-inline/#separate-resource","title":"Separate resource","text":"<p>While inlining might make a lot of sense for many APIs, there are also good reasons to separate them out. These arguments may not be conclusive, but can help steer in the right direction.</p>"},{"location":"topics/guide-new-resource-vs-inline/#category-1-the-obvious-new-resource","title":"Category 1: the obvious new resource","text":"<ul> <li>It is a new resource with it's own lifecycle, own API endpoints (at least <code>Update</code> and <code>Delete</code>), it just feels natural to put it in a separate resource</li> </ul>"},{"location":"topics/guide-new-resource-vs-inline/#category-2-child-resources","title":"Category 2: child resources","text":"<ul> <li>It does have it's own unique Resource ID or name (i.e. <code>&lt;parentId&gt;/subResource/MySubResourceName</code>)</li> <li>It has it's own API endpoint for <code>Create</code>, <code>Update</code> and <code>Delete</code> actions</li> <li>It needs more permissions on the already existing resource than the current parent resource requires (i.e. Key Vault Key Rotation Policies require more permissions than the Key Vault Key it really belongs to)</li> <li>Control Plane vs Data plane: the functionality is acting on the Data Plane instead of Control Plane of the service or vice versa. (i.e. Azure Storage Account management vs the actual Blobs put in there, Azure Key Vault management vs the Keys/Certs/Secrets inside)</li> <li>Its functionality and therefore the scope of the resource crosses team/security boundaries (i.e. Infra team vs Application team).</li> </ul>"},{"location":"topics/guide-new-resource-vs-inline/#category-3-relations-between-resources-it-is-complicated","title":"Category 3: relations between resources (\"It is complicated \")","text":"<ul> <li>It is a mediator: there is a seperate endpoint to create a relation between two existing resources</li> <li>It requires more permissions on another resource to create the connection than to create the resource itself (i.e. connecting a NSG resource to a Subnet)</li> </ul>"},{"location":"topics/guide-new-resource-vs-inline/#both-inline-and-separate","title":"Both inline and separate","text":"<p>It might be that there are multiple use-cases and scenarios necessary. Sometimes it makes sense to create it inline, sometimes it makes more sense to seperate them.</p> <p>This requires cautiousness from both the implementer and the user. In most cases it should be explained with some notes in the <code>docs</code>. Within the inline resource implementation it requires that it doesn't delete or update properties created externally when it is not explicitly configured in the resource. For the user this might have the drawback that the inlined resource is not strict in enforcing the existing inlined properties. Mixed use within the same context might end up in a mess and is adviced not to do.</p> <p>A few examples of resources which are both inlined and seperate resources: - Subnets (part of VNet resource as well) - NSG rules (part of NSG resource as well) - Key Vault permissions (part of Key Vault resource as well)</p>"},{"location":"topics/guide-new-resource/","title":"Guide: New Resource","text":"<p>This guide covers adding a new Resource to a Service Package, see adding a New Service Package if the Service Package doesn't exist yet.</p>"},{"location":"topics/guide-new-resource/#related-topics","title":"Related Topics","text":"<ul> <li>Acceptance Testing</li> <li>Our Recommendations for opening a Pull Request</li> </ul>"},{"location":"topics/guide-new-resource/#stages","title":"Stages","text":"<p>At this point in time the AzureRM Provider supports both Typed and Untyped Resources - more information can be found in the High Level Overview.</p> <p>This guide covers adding a new Typed Resource, which makes uses the Typed SDK within this repository, which requires the following steps:</p> <ol> <li>Ensure all the dependencies are installed (see Building the Provider).</li> <li>Add an SDK Client (if required).</li> <li>Define the Resource ID.</li> <li>Scaffold an empty/new Resource.</li> <li>Register the new Resource.</li> <li>Add Acceptance Test(s) for this Resource.</li> <li>Run the Acceptance Test(s).</li> <li>Add Documentation for this Resource.</li> <li>Send the Pull Request.</li> </ol> <p>We'll go through each of those steps in turn, presuming that we're creating a Resource for a Resource Group.</p>"},{"location":"topics/guide-new-resource/#step-1-ensure-the-tools-are-installed","title":"Step 1: Ensure the Tools are installed","text":"<p>See Building the Provider.</p>"},{"location":"topics/guide-new-resource/#step-2-add-an-sdk-client-if-required","title":"Step 2: Add an SDK Client (if required)","text":"<p>This section covers how to add and configure the SDK Client.</p> <p>Determining which SDK Client you should be using is a little complicated unfortunately.</p> <p>The Client for the Service Package can be found in <code>./internal/services/{name}/client/client.go</code> - and we can add an instance of the SDK Client we want to use (here <code>resources.GroupsClient</code>) and configure it (adding credentials etc):</p> <pre><code>package client\n\nimport (\n\"github.com/Azure/azure-sdk-for-go/services/resources/mgmt/2020-06-01/resources\" // nolint: staticcheck\n\"github.com/hashicorp/terraform-provider-azurerm/internal/common\"\n)\n\ntype Client struct {\nGroupsClient *resources.GroupsClient\n}\n\nfunc NewClient(o *common.ClientOptions) *Client {\ngroupsClient := resources.NewGroupsClientWithBaseURI(o.ResourceManagerEndpoint, o.SubscriptionId)\no.ConfigureClient(&amp;groupsClient.Client, o.ResourceManagerAuthorizer)\n\n// ...\n\nreturn &amp;Client{\nGroupsClient: &amp;groupsClient,\n}\n}\n</code></pre> <p>A few things of note here:</p> <ol> <li>The field <code>GroupsClient</code> within the struct is a pointer, meaning that if it's not initialized the Provider will crash/panic - which is intentional to avoid using an unconfigured client (which will have no credentials, and cause misleading errors).</li> <li>When creating the client, note that we're using <code>NewGroupsClientWithBaseURI</code> (and not <code>NewGroupsClient</code>) from the SDK - this is intentional since we want to specify the Resource Manager endpoint for the Azure Environment (e.g. Public, China, US Government etc) that the credentials we're using are connected to.</li> <li>The call to <code>o.ConfigureClient</code> configures the authorization token which should be used for this SDK Client - in most cases <code>ResourceManagerAuthorizer</code> is the authorizer you want to use.</li> </ol> <p>At this point, this SDK Client should be usable within the Resource via:</p> <pre><code>client := metadata.Client.{ServicePackage}.{ClientField}\n</code></pre> <p>For example, in this case:</p> <pre><code>client := metadata.Client.Resource.GroupsClient\n</code></pre>"},{"location":"topics/guide-new-resource/#step-3-define-the-resource-id","title":"Step 3: Define the Resource ID","text":"<p>Next we're going to generate a Resource ID Struct, Parser and Validator for the specific Azure Resource that we're working with, in this case for a Resource Group.</p> <p>We have some automation within the codebase which generates all of that using <code>go:generate</code> commands - what this means is that we can add a single line to the <code>resourceids.go</code> file within the Service Package (in this case <code>./internal/services/resource/resourceids.go</code>) to generate these.</p> <p>An example of this is shown below:</p> <pre><code>package resource\n\n//go:generate go run ../../tools/generator-resource-id/main.go -path=./ -name=ResourceGroupExample -id=/subscriptions/12345678-1234-9876-4563-123456789012/resourceGroups/group1\n</code></pre> <p>In this case, you need to specify the <code>name</code> the Resource (in this case <code>ResourceGroupExample</code>) and the <code>id</code> which is an example of this Resource ID (in this case <code>/subscriptions/12345678-1234-9876-4563-123456789012/resourceGroups/group1</code>).</p> <p>The segments of the Resource ID should be camelCased (e.g. <code>resourceGroups</code> rather than <code>resourcegroups</code>) per the Azure API Specification - see Azure Resource IDs in the Glossary for more information.</p> <p>You can generate the Resource ID Struct, Parser and Validation functions by running <code>make generate</code> - which will output the following files:</p> <ul> <li><code>./internal/service/resource/parse/resource_group_example.go</code> - contains the Resource ID Struct, Formatter and Parser.</li> <li><code>./internal/service/resource/parse/resource_group_example_test.go</code> - contains tests for those ^.</li> <li><code>./internal/service/resource/validate/resource_group_example_id.go</code> - contains Terraform validation functions for the Resource ID.</li> </ul> <p>These types can then be used in the Resource we're creating below.</p>"},{"location":"topics/guide-new-resource/#step-4-scaffold-an-emptynew-resource","title":"Step 4: Scaffold an empty/new Resource","text":"<p>Since we're creating a Resource for a Resource Group, which is a part of the Resources API - we'll want to create an empty Go file within the Service Package for Resources, which is located at <code>./internal/services/resource</code>.</p> <p>In this case, this'd be a file called <code>resource_group_example_resource.go</code>, which we'll start out with the following:</p> <p>Note: We'd normally name this file <code>resource_group_resource.go</code> - but there's an existing Resource for Resource Groups, so we're appending <code>example</code> to the name throughout this guide.</p> <pre><code>package resource\n\nimport \"github.com/hashicorp/terraform-provider-azurerm/internal/sdk\"\n\nvar _ sdk.Resource = ResourceGroupExampleResource{}\n\ntype ResourceGroupExampleResource struct {}\n</code></pre> <p>Note: Your editor may show a suggestion to implement the methods defined in <code>sdk.Resource</code> for the <code>ResourceGroupExampleResource</code> struct - we'd recommend holding off the first time around to explain each of the methods.</p> <p>In this case the interface <code>sdk.Resource</code> defines all of the methods required for a Resource which the newly created struct for the Resource Group Resource need to implement, which are:</p> <pre><code>type Resource interface {\nArguments() map[string]*schema.Schema\nAttributes() map[string]*schema.Schema\nModelObject() interface{}\nResourceType() string\nCreate() ResourceFunc\nRead() ResourceFunc\nDelete() ResourceFunc\nIDValidationFunc() pluginsdk.SchemaValidateFunc\n}\n</code></pre> <p>To go through these in turn:</p> <ul> <li><code>Arguments</code> returns a list of schema fields which are user-specifiable - either Required or Optional.</li> <li><code>Attributes</code> returns a list of schema fields which are Computed (read-only).</li> <li><code>ModelObject</code> returns a reference to a Go struct which is used as the Model for this Resource (this can also return <code>nil</code> if there's no model).</li> <li><code>ResourceType</code> returns the name of this resource within the Provider (for example <code>azurerm_resource_group_example</code>).</li> <li><code>Create</code> returns a function defining both the Timeout and the Create function (which creates this Resource Group using the Azure API) for this Resource.</li> <li><code>Read</code> returns a function defining both the Timeout and the Read function (which retrieves information from the Azure API) for this Resource.</li> <li><code>Delete</code> returns a function defining both the Timeout and the Delete function (which deletes this Resource Group using the Azure API) for this Resource.</li> <li><code>IDValidationFunc</code> returns a function which validates the Resource ID provided during <code>terraform import</code> to ensure it matches what we expect for this Resource.</li> </ul> <pre><code>func (ResourceGroupExampleResource) Arguments() map[string]*pluginsdk.Schema {\nreturn map[string]*pluginsdk.Schema{\n\"name\": {\nType:     pluginsdk.TypeString,\nRequired: true,\n},\n\n\"location\": commonschema.Location(),\n\n\"tags\": tags.Schema(),\n}\n}\n\nfunc (ResourceGroupExampleResource) Attributes() map[string]*pluginsdk.Schema {\nreturn map[string]*pluginsdk.Schema{}\n}\n\nfunc (ResourceGroupExampleResource) ModelObject() interface{} {\nreturn nil\n}\n\nfunc (ResourceGroupExampleResource) ResourceType() string {\nreturn \"azurerm_resource_group_example\"\n}\n</code></pre> <p>In this case we're using the resource type <code>azurerm_resource_group_example</code> as an existing Resource for <code>azurerm_resource_group</code> exists and the names need to be unique.</p> <p>These functions define a Resource called <code>azurerm_resource_group_example</code>, which has two Required arguments (<code>name</code> and <code>location</code>) and one Optional argument (<code>tags</code>). We'll come back to <code>ModelObject</code> later.</p> <p>Let's start by implementing the Create function:</p> <pre><code>func (r ResourceGroupExampleResource) Create() sdk.ResourceFunc {\nreturn sdk.ResourceFunc{\n// the Timeout is how long Terraform should wait for this function to run before returning an error\n// whilst 30 minutes may initially seem excessive, we set this as a default to account for rate\n// limiting - but having this here means that users can override this in their config as necessary\nTimeout: 30 * time.Minute,\n\n// the Func returns a function which retrieves the current state of the Resource Group into the state\nFunc: func(ctx context.Context, metadata sdk.ResourceMetaData) error {\nclient := metadata.Client.Resource.GroupsClient\n\n// retrieve the Name for this Resource Group from the Terraform Config\n// and then create a Resource ID for this Resource Group\n// using the Subscription ID &amp; name \nsubscriptionId := metadata.Client.Account.SubscriptionId\nname := metadata.ResourceData.Get(\"name\").(string)\nid := parse.NewResourceGroupID(subscriptionId, name)\n\n// then we want to check for the presence of an existing resource with this name\n// this is because the Azure API uses the `name` as a unique idenfitier and Upserts\n// so we don't want to unintentionally adopt this resource by using the same name\nexisting, err := client.Get(ctx, id.ResourceGroup)\nif err != nil &amp;&amp; !utils.ResponseWasNotFound(existing.Response) {\nreturn fmt.Errorf(\"checking for presence of existing %s: %+v\", id, err)\n}\nif !utils.ResponseWasNotFound(existing.Response) {\nreturn metadata.ResourceRequiresImport(r.ResourceType(), id)\n}\n\n// create the Resource Group\nparam := resources.Group{\nLocation: utils.String(location.Normalize(metadata.ResourceData.Get(\"location\").(string))),\nTags:     tags.Expand(metadata.ResourceData.Get(\"tags\").(map[string]interface{})),\n}\nif _, err := client.CreateOrUpdate(ctx, id.ResourceGroup, param); err != nil {\nreturn fmt.Errorf(\"creating %s: %+v\", id, err)\n}\n\n// set the Resource ID, meaning that we track this resource\nmetadata.SetID(id)\nreturn nil\n},\n}\n}\n</code></pre> <p>Let's implement the Update function:</p> <pre><code>func (r ResourceGroupExampleResource) Update() sdk.ResourceFunc {\nreturn sdk.ResourceFunc{\n// the Timeout is how long Terraform should wait for this function to run before returning an error\n// whilst 30 minutes may initially seem excessive, we set this as a default to account for rate\n// limiting - but having this here means that users can override this in their config as necessary\nTimeout: 30 * time.Minute,\n\n// the Func returns a function which retrieves the current state of the Resource Group into the state\nFunc: func(ctx context.Context, metadata sdk.ResourceMetaData) error {\nclient := metadata.Client.Resource.GroupsClient\n\n// parse the existing Resource ID from the State\nid, err := parse.ResourceGroupID(metadata.ResourceData.Get(\"id\").(string))\nif err != nil {\nreturn err\n}\n\n// update the Resource Group\n// NOTE: for a more complex resource we'd recommend retrieving the existing Resource from the\n// API and then conditionally updating it when fields in the config have been updated, which\n// can be determined by using `d.HasChanges` - for example:\n//\n//   existing, err := client.Get(ctx, id.ResourceGroup)\n//   if err != nil {\n//     return fmt.Errorf(\"retrieving existing %s: %+v\", id, err)\n//   }\n//   if d.HasChanges(\"tags\") {\n//     existing.Tags = tags.Expand(metadata.ResourceData.Get(\"tags\").(map[string]interface{}))\n//   }\n//\n// doing so allows users to take advantage of Terraform's `ignore_changes` functionality.\n//\n// However since a Resource Group only has one field which is updatable (tags) so in this case we'll only\n// enter the update function if `tags` has been updated.\nparam := resources.Group{\nLocation: utils.String(location.Normalize(metadata.ResourceData.Get(\"location\").(string))),\nTags:     tags.Expand(metadata.ResourceData.Get(\"tags\").(map[string]interface{})),\n}\nif _, err := client.CreateOrUpdate(ctx, id.ResourceGroup, param); err != nil {\nreturn fmt.Errorf(\"creating %s: %+v\", id, err)\n}\n\n// set the Resource ID, meaning that we track this resource\nmetadata.SetID(id)\nreturn nil\n},\n}\n}\n</code></pre> <p>Next up, let's implement the Read function - which retrieves the information about the Resource Group from Azure:</p> <pre><code>func (ResourceGroupExampleResource) Read() sdk.ResourceFunc {\nreturn sdk.ResourceFunc{\n// the Timeout is how long Terraform should wait for this function to run before returning an error\n// whilst 5 minutes may initially seem excessive, we set this as a default to account for rate\n// limiting - but having this here means that users can override this in their config as necessary\nTimeout: 5 * time.Minute,\n\n// the Func returns a function which looks up the state of the Resource Group and sets it into the state\nFunc: func(ctx context.Context, metadata sdk.ResourceMetaData) error {\nclient := metadata.Client.Resource.GroupsClient\n\n// parse the Resource Group ID from the `id` field\nid, err := parse.ResourceGroupID(metadata.ResourceData.Id())\nif err != nil {\nreturn err\n}\n\n// then retrieve the Resource Group by its Name\nresp, err := client.Get(ctx, id.ResourceGroup)\nif err != nil {\n// if the Resource Group doesn't exist (e.g. we get a 404 Not Found)\n// since this is a Resource (e.g. we created it/it was imported into the state)\n// it previously existed - so we must mark this as \"gone\" for Terraform\nif utils.ResponseWasNotFound(resp.Response) {\nreturn metadata.MarkAsGone(id)\n}\n\n// otherwise it's a genuine error (auth/api error etc) so raise it\n// there should be enough context for the user to interpret the error\n// or raise a bug report if there's something we should handle\nreturn fmt.Errorf(\"retrieving %s: %+v\", id, err)\n}\n\n// at this point we can set information about this Resource Group into the State\n// identifier fields such as the name, resource group name to name a few need to be sourced\n// from the Resource ID instead of the API response\nmetadata.ResourceData.Set(\"name\", id.ResourceGroup)\n\n// the SDK will return a Model as well as a nested Properties object for the resource\n// for readability and consistency we assign the Model to a variable and nil check as shown below.\n// since the SDK accounts for responses where the Model is nil we do not need to throw an error if\n// the Model is nil since this will be caught earlier on. We still nil check to prevent the provider from\n// crashing.\nif model := resp.Model; model != nil {\n// the Location and Tags fields are a little different - and we have a couple of normalization\n// functions for these.\n\n// whilst this may seem like a weird thing to call out in an example, because these two fields\n// are present on the majority of resources, we hope it explains why they're a little different\n\n// in this case the Location can be returned in various different forms, for example\n// \"West Europe\", \"WestEurope\" or \"westeurope\" - as such we normalize these into a\n// lower-cased singular word with no spaces (e.g. \"westeurope\") so this is consistent\n// for users\nmetadata.ResourceData.Set(\"location\", location.NormalizeNilable(model.Location))\n\nif props := model.Properties; props != nil {\n// if there are properties to set into state do that here\n}\n\n// (as above) Tags are a little different, so we have a dedicated helper function\n// to flatten these consistently across the Provider\nif err := tags.FlattenAndSet(metadata.ResourceData, model.Tags); err != nil {\nreturn fmt.Errorf(\"setting `tags`: %+v\", err)\n}\n}       return nil\n},\n}\n}\n</code></pre> <p>Next we can add the Delete function:</p> <pre><code>func (ResourceGroupExampleResource) Delete() sdk.ResourceFunc {\nreturn sdk.ResourceFunc{\n// the Timeout is how long Terraform should wait for this function to run before returning an error\n// whilst 30 minutes may initially seem excessive, it can take a while to delete the nested items\n// particularly if we're rate-limited - but users can override this in their config as necessary\nTimeout: 30 * time.Minute,\n\n// the Func returns a function which deletes the Resource Group\nFunc: func(ctx context.Context, metadata sdk.ResourceMetaData) error {\nclient := metadata.Client.Resource.GroupsClient\n\nid, err := parse.ResourceGroupID(metadata.ResourceData.Id())\nif err != nil {\nreturn err\n}\n\n// NOTE: this is an optional parameter in the SDK we're not concerned with, so we pass an empty string instead\nforceDeletionTypes := \"\"\n\n// trigger the deletion of the Resource Group\nfuture, err := client.Delete(ctx, id.ResourceGroup, forceDeletionTypes)\nif err != nil {\nreturn fmt.Errorf(\"deleting %s: %+v\", *id, err)\n}\n\n// keep polling until the Resource Group has been deleted\nif err := future.WaitForCompletionRef(ctx, client.Client); err != nil {\nreturn fmt.Errorf(\"waiting for the deletion of %s: %+v\", *id, err)\n}\n\nreturn nil\n},\n}\n}\n</code></pre> <p>Finally we can add the <code>IDValidationFunc</code> function:</p> <pre><code>func (ResourceGroupExampleResource) IDValidationFunc() pluginsdk.SchemaValidateFunc {\nreturn validate.ResourceGroupID\n}\n</code></pre> <p>At this point the finished Resource should look like (including imports):</p> <pre><code>package resource\n\nimport (\n\"context\"\n\"fmt\"\n\"time\"\n\n\"github.com/Azure/azure-sdk-for-go/services/resources/mgmt/2020-06-01/resources\" // nolint: staticcheck\n\"github.com/hashicorp/go-azure-helpers/resourcemanager/commonschema\"\n\"github.com/hashicorp/go-azure-helpers/resourcemanager/location\"\n\"github.com/hashicorp/terraform-provider-azurerm/internal/sdk\"\n\"github.com/hashicorp/terraform-provider-azurerm/internal/services/resource/parse\"\n\"github.com/hashicorp/terraform-provider-azurerm/internal/services/resource/validate\"\n\"github.com/hashicorp/terraform-provider-azurerm/internal/tags\"\n\"github.com/hashicorp/terraform-provider-azurerm/internal/tf/pluginsdk\"\n\"github.com/hashicorp/terraform-provider-azurerm/utils\"\n)\n\nvar _ sdk.Resource = ResourceGroupExampleResource{}\n\ntype ResourceGroupExampleResource struct{}\n\nfunc (ResourceGroupExampleResource) Arguments() map[string]*pluginsdk.Schema {\nreturn map[string]*pluginsdk.Schema{\n\"name\": {\nType:     pluginsdk.TypeString,\nRequired: true,\n},\n\n\"location\": commonschema.Location(),\n\n\"tags\": tags.Schema(),\n}\n}\n\nfunc (ResourceGroupExampleResource) Attributes() map[string]*pluginsdk.Schema {\nreturn map[string]*pluginsdk.Schema{}\n}\n\nfunc (ResourceGroupExampleResource) ModelObject() interface{} {\nreturn nil\n}\n\nfunc (ResourceGroupExampleResource) ResourceType() string {\nreturn \"azurerm_resource_group_example\"\n}\n\nfunc (r ResourceGroupExampleResource) Create() sdk.ResourceFunc {\nreturn sdk.ResourceFunc{\n// the Timeout is how long Terraform should wait for this function to run before returning an error\n// whilst 30 minutes may initially seem excessive, we set this as a default to account for rate\n// limiting - but having this here means that users can override this in their config as necessary\nTimeout: 30 * time.Minute,\n\n// the Func returns a function which retrieves the current state of the Resource Group into the state\nFunc: func(ctx context.Context, metadata sdk.ResourceMetaData) error {\nclient := metadata.Client.Resource.GroupsClient\n\n// retrieve the Name for this Resource Group from the Terraform Config\n// and then create a Resource ID for this Resource Group\n// using the Subscription ID &amp; name\nsubscriptionId := metadata.Client.Account.SubscriptionId\nname := metadata.ResourceData.Get(\"name\").(string)\nid := parse.NewResourceGroupID(subscriptionId, name)\n\n// then we want to check for the presence of an existing resource with this name\n// this is because the Azure API uses the `name` as a unique idenfitier and Upserts\n// so we don't want to unintentionally adopt this resource by using the same name\nexisting, err := client.Get(ctx, id.ResourceGroup)\nif err != nil &amp;&amp; !utils.ResponseWasNotFound(existing.Response) {\nreturn fmt.Errorf(\"checking for presence of existing %s: %+v\", id, err)\n}\nif !utils.ResponseWasNotFound(existing.Response) {\nreturn metadata.ResourceRequiresImport(r.ResourceType(), id)\n}\n\n// create the Resource Group\nparam := resources.Group{\nLocation: utils.String(location.Normalize(metadata.ResourceData.Get(\"location\").(string))),\nTags:     tags.Expand(metadata.ResourceData.Get(\"tags\").(map[string]interface{})),\n}\nif _, err := client.CreateOrUpdate(ctx, id.ResourceGroup, param); err != nil {\nreturn fmt.Errorf(\"creating %s: %+v\", id, err)\n}\n\n// set the Resource ID, meaning that we track this resource\nmetadata.SetID(id)\nreturn nil\n},\n}\n}\n\nfunc (r ResourceGroupExampleResource) Update() sdk.ResourceFunc {\nreturn sdk.ResourceFunc{\n// the Timeout is how long Terraform should wait for this function to run before returning an error\n// whilst 30 minutes may initially seem excessive, we set this as a default to account for rate\n// limiting - but having this here means that users can override this in their config as necessary\nTimeout: 30 * time.Minute,\n\n// the Func returns a function which retrieves the current state of the Resource Group into the state\nFunc: func(ctx context.Context, metadata sdk.ResourceMetaData) error {\nclient := metadata.Client.Resource.GroupsClient\n\n// parse the existing Resource ID from the State\nid, err := parse.ResourceGroupID(metadata.ResourceData.Get(\"id\").(string))\nif err != nil {\nreturn err\n}\n\n// update the Resource Group\n// NOTE: for a more complex resource we'd recommend retrieving the existing Resource from the\n// API and then conditionally updating it when fields in the config have been updated, which\n// can be determined by using `d.HasChanges` - for example:\n//\n//   existing, err := client.Get(ctx, id.ResourceGroup)\n//   if err != nil {\n//     return fmt.Errorf(\"retrieving existing %s: %+v\", id, err)\n//   }\n//   if d.HasChanges(\"tags\") {\n//     existing.Tags = tags.Expand(metadata.ResourceData.Get(\"tags\").(map[string]interface{}))\n//   }\n//\n// doing so allows users to take advantage of Terraform's `ignore_changes` functionality.\n//\n// However since a Resource Group only has one field which is updatable (tags) so in this case we'll only\n// enter the update function if `tags` has been updated.\nparam := resources.Group{\nLocation: utils.String(location.Normalize(metadata.ResourceData.Get(\"location\").(string))),\nTags:     tags.Expand(metadata.ResourceData.Get(\"tags\").(map[string]interface{})),\n}\nif _, err := client.CreateOrUpdate(ctx, id.ResourceGroup, param); err != nil {\nreturn fmt.Errorf(\"creating %s: %+v\", id, err)\n}\n\n// set the Resource ID, meaning that we track this resource\nmetadata.SetID(id)\nreturn nil\n},\n}\n}\n\nfunc (ResourceGroupExampleResource) Read() sdk.ResourceFunc {\nreturn sdk.ResourceFunc{\n// the Timeout is how long Terraform should wait for this function to run before returning an error\n// whilst 5 minutes may initially seem excessive, we set this as a default to account for rate\n// limiting - but having this here means that users can override this in their config as necessary\nTimeout: 5 * time.Minute,\n\n// the Func returns a function which looks up the state of the Resource Group and sets it into the state\nFunc: func(ctx context.Context, metadata sdk.ResourceMetaData) error {\nclient := metadata.Client.Resource.GroupsClient\n\n// parse the Resource Group ID from the `id` field\nid, err := parse.ResourceGroupID(metadata.ResourceData.Id())\nif err != nil {\nreturn err\n}\n\n// then retrieve the Resource Group by its Name\nresp, err := client.Get(ctx, id.ResourceGroup)\nif err != nil {\n// if the Resource Group doesn't exist (e.g. we get a 404 Not Found)\n// since this is a Resource (e.g. we created it/it was imported into the state)\n// it previously existed - so we must mark this as \"gone\" for Terraform\nif utils.ResponseWasNotFound(resp.Response) {\nreturn metadata.MarkAsGone(id)\n}\n\n// otherwise it's a genuine error (auth/api error etc) so raise it\n// there should be enough context for the user to interpret the error\n// or raise a bug report if there's something we should handle\nreturn fmt.Errorf(\"retrieving %s: %+v\", id, err)\n}\n\n// at this point we can set information about this Resource Group into the State\nmetadata.ResourceData.Set(\"name\", id.ResourceGroup)\n\n// the Location and Tags fields are a little different - and we have a couple of normalization\n// functions for these.\n//\n// whilst this may seem like a weird thing to call out in an example, because these two fields\n// are present on the majority of resources, we hope it explains why they're a little different\n//\n// in this case the Location can be returned in various different forms, for example\n// \"West Europe\", \"WestEurope\" or \"westeurope\" - as such we normalize these into a\n// lower-cased singular word with no spaces (e.g. \"westeurope\") so this is consistent\n// for users\nmetadata.ResourceData.Set(\"location\", location.NormalizeNilable(resp.Location))\n\n// (as above) Tags are a little different, so we have a dedicated helper function\n// to flatten these consistently across the Provider\nreturn tags.FlattenAndSet(metadata.ResourceData, resp.Tags)\n},\n}\n}\n\nfunc (ResourceGroupExampleResource) Delete() sdk.ResourceFunc {\nreturn sdk.ResourceFunc{\n// the Timeout is how long Terraform should wait for this function to run before returning an error\n// whilst 30 minutes may initially seem excessive, it can take a while to delete the nested items\n// particularly if we're rate-limited - but users can override this in their config as necessary\nTimeout: 30 * time.Minute,\n\n// the Func returns a function which deletes the Resource Group\nFunc: func(ctx context.Context, metadata sdk.ResourceMetaData) error {\nclient := metadata.Client.Resource.GroupsClient\n\nid, err := parse.ResourceGroupID(metadata.ResourceData.Id())\nif err != nil {\nreturn err\n}\n\n// NOTE: this is an optional parameter in the SDK we're not concerned with, so we pass an empty string instead\nforceDeletionTypes := \"\"\n\n// trigger the deletion of the Resource Group\nfuture, err := client.Delete(ctx, id.ResourceGroup, forceDeletionTypes)\nif err != nil {\nreturn fmt.Errorf(\"deleting %s: %+v\", *id, err)\n}\n\n// keep polling until the Resource Group has been deleted\nif err := future.WaitForCompletionRef(ctx, client.Client); err != nil {\nreturn fmt.Errorf(\"waiting for the deletion of %s: %+v\", *id, err)\n}\n\nreturn nil\n},\n}\n}\n\nfunc (ResourceGroupExampleResource) IDValidationFunc() pluginsdk.SchemaValidateFunc {\nreturn validate.ResourceGroupID\n}\n</code></pre> <p>At this point in time this Resource is now code-complete - there's an optional extension to make this cleaner by using a Typed Model, however this isn't necessary.</p>"},{"location":"topics/guide-new-resource/#step-5-register-the-new-resource","title":"Step 5: Register the new Resource","text":"<p>Resources are registered within the <code>registration.go</code> within each Service Package - and should look something like this:</p> <pre><code>package resource\n\nimport \"github.com/hashicorp/terraform-provider-azurerm/internal/sdk\"\n\nvar _ sdk.TypedServiceRegistration = Registration{}\n\ntype Registration struct{}\n\n// ...\n\n// Resources returns a list of Resources supported by this Service\nfunc (r Registration) Resources() []sdk.Resource {\nreturn []sdk.Resource{}\n}\n</code></pre> <p>Note: It's possible that the Service Registration (above) doesn't currently support Typed Resources, in which case you may need to add the following:</p> <pre><code>var _ sdk.TypedServiceRegistration = Registration{}\n\ntype Registration struct {\n}\n\nfunc (Registration) Name() string {\nreturn \"Some Service\"\n}\n\nfunc (Registration) DataSources() []sdk.DataSource {\nreturn []sdk.DataSource{}\n}\n\nfunc (Registration) Resources() []sdk.Resource {\nreturn []sdk.Resource{}\n}\n\nfunc (Registration) WebsiteCategories() []string {\nreturn []string{\n\"Some Service\",\n}\n}\n</code></pre> <p>In this case you'll also need to add a line to register this Service Registration in the list of Typed Service Registrations.</p> <p>To register the Resource we need to add an instance of the struct used for the Resource to the list of Resources, for example:</p> <pre><code>// Resources returns a list of Resources supported by this Service\nfunc (Registration) Resources() []sdk.Resource {\nreturn []sdk.Resource{\nResourceGroupExampleResource{}, }\n}\n</code></pre> <p>At this point the Resource is registered, as when the Azure Provider builds up a list of supported Resources during initialization, it parses each of the Service Registrations to put together a definitive list of the Resources that we support.</p> <p>This means that if you Build the Provider, at this point you should be able to apply the following Resource:</p> <pre><code>provider \"azurerm\" {\n  features {}\n}\n\nresource \"azurerm_resource_group_example\" \"test\" {\n  name     = \"example-resources\"\n  location = \"West Europe\"\n}\n\noutput \"id\" {\n  value = azurerm_resource_group_example.test.id\n}\n</code></pre>"},{"location":"topics/guide-new-resource/#step-6-add-acceptance-tests-for-this-resource","title":"Step 6: Add Acceptance Test(s) for this Resource","text":"<p>We're going to test the Resource that we've just built by dynamically provisioning a Resource Group using the new <code>azurerm_resource_group_example</code> Resource.</p> <p>In Go tests are expected to be in a file name in the format <code>{original_file_name}_test.go</code> - in our case that'd be <code>resource_group_example_resource_test.go</code>, into which we'll want to add:</p> <pre><code>package resource_test\n\nimport (\n\"context\"\n\"fmt\"\n\"testing\"\n\n\"github.com/hashicorp/terraform-provider-azurerm/internal/acceptance\"\n\"github.com/hashicorp/terraform-provider-azurerm/internal/clients\"\n\"github.com/hashicorp/terraform-provider-azurerm/internal/services/resource/parse\"\n\"github.com/hashicorp/terraform-provider-azurerm/internal/tf/pluginsdk\"\n\"github.com/hashicorp/terraform-provider-azurerm/utils\"\n)\n\ntype ResourceGroupExampleTestResource struct{}\n\nfunc TestAccResourceGroupExample_basic(t *testing.T) {\ndata := acceptance.BuildTestData(t, \"azurerm_resource_group_example\", \"test\")\ntestResource := ResourceGroupExampleTestResource{}\ndata.ResourceTest(t, testResource, []acceptance.TestStep{\ndata.ApplyStep(testResource.basicConfig, testResource),\ndata.ImportStep(),\n})\n}\n\nfunc TestAccResourceGroupExample_requiresImport(t *testing.T) {\ndata := acceptance.BuildTestData(t, \"azurerm_resource_group_example\", \"test\")\ntestResource := ResourceGroupExampleTestResource{}\ndata.ResourceTest(t, testResource, []acceptance.TestStep{\ndata.ApplyStep(testResource.basicConfig, testResource),\ndata.RequiresImportErrorStep(testResource.requiresImportConfig),\n})\n}\n\nfunc TestAccResourceGroupExample_complete(t *testing.T) {\ndata := acceptance.BuildTestData(t, \"azurerm_resource_group_example\", \"test\")\ntestResource := ResourceGroupExampleTestResource{}\ndata.ResourceTest(t, testResource, []acceptance.TestStep{\ndata.ApplyStep(testResource.completeConfig, testResource),\ndata.ImportStep(),\ndata.ApplyStep(testResource.basicConfig, testResource),\ndata.ImportStep(),\ndata.ApplyStep(testResource.completeConfig, testResource),\ndata.ImportStep(),\n})\n}\n\nfunc (ResourceGroupExampleTestResource) Exists(ctx context.Context, client *clients.Client, state *pluginsdk.InstanceState) (*bool, error) {\nid, err := parse.ResourceGroupID(state.ID)\nif err != nil {\nreturn nil, err\n}\n\nresp, err := client.Resource.GroupsClient.Get(ctx, id.ResourceGroup)\nif err != nil {\nreturn nil, fmt.Errorf(\"retrieving %s: %+v\", *id, err)\n}\n\nreturn utils.Bool(resp.Properties != nil), nil\n}\n\nfunc (ResourceGroupExampleTestResource) basicConfig(data acceptance.TestData) string {\nreturn fmt.Sprintf(`\nprovider \"azurerm\" {\n  features {}\n}\n\nresource \"azurerm_resource_group_example\" \"test\" {\n  name     = \"acctestRG-%d\"\n  location = \"%s\"\n}\n`, data.RandomInteger, data.Locations.Primary)\n}\n\nfunc (r ResourceGroupExampleTestResource) requiresImportConfig(data acceptance.TestData) string {\ntemplate := r.basicConfig(data)\nreturn fmt.Sprintf(`\n%s\n\nresource \"azurerm_resource_group_example\" \"import\" {\n  name     = azurerm_resource_group_example.test.name\n  location = azurerm_resource_group_example.test.location\n}\n`, template)\n}\n\nfunc (ResourceGroupExampleTestResource) completeConfig(data acceptance.TestData) string {\nreturn fmt.Sprintf(`\nprovider \"azurerm\" {\n  features {}\n}\n\nresource \"azurerm_resource_group_example\" \"test\" {\n  name     = \"acctestRG-%d\"\n  location = \"%s\"\n\n  tags = {\n    Hello = \"World\"\n  }\n}\n`, data.RandomInteger, data.Locations.Primary)\n}\n</code></pre> <p>There's a more detailed breakdown of how this works in the Acceptance Testing reference - but to summarize what's going on here:</p> <ol> <li>Test Terraform Configurations are defined as methods on the struct <code>ResourceGroupExampleResource</code> so that they're easily accessible (this helps to avoid them being unintentionally used in other resources).</li> <li>The <code>acceptance.TestData</code> object contains a number of helpers, including both random integers, strings and the Azure Locations where resources should be provisioned - which are used to ensure when tests are run in parallel that we provision unique resources for testing purposes.</li> <li>The <code>ApplyStep</code>'s apply the Terraform Configuration specified and then assert there's no changes after (e.g. <code>terraform apply</code> and then checking that <code>terraform plan</code> shows no changes).</li> <li>The <code>ImportStep</code> takes the Resource ID for the Resource and runs <code>terraform import azurerm_resource_group_example.test {resourceId}</code>, checking that the fields defined in the state match the fields returned from the Read function.</li> <li>We append <code>_test</code> to the Go package name (e.g. <code>resource_test</code>) since we need to be able to access both the <code>resource</code> package and the <code>acceptance</code> package (which is a circular reference, otherwise).</li> </ol> <p>At this point we should be able to run this test.</p>"},{"location":"topics/guide-new-resource/#step-7-run-the-acceptance-tests","title":"Step 7: Run the Acceptance Test(s)","text":"<p>Detailed instructions on Running the Tests can be found in this guide - when a Service Principal is configured you can run the test above using:</p> <pre><code>make acctests SERVICE='resource' TESTARGS='-run=TestAccResourceGroupExample_' TESTTIMEOUT='60m'\n</code></pre> <p>Note: We're using the test prefix <code>TestAccResourceGroupExample_</code> and not the name of an individual test, but you can do that too by specifying <code>\"(TestName1|TestName2)\"</code> etc</p> <p>Which should output:</p> <pre><code>==&gt; Checking that code complies with gofmt requirements...\n==&gt; Checking that Custom Timeouts are used...\n==&gt; Checking that acceptance test packages are used...\nTF_ACC=1 go test -v ./internal/services/resource -run=TestAccResourceGroupExample_ -timeout 60m -ldflags=\"-X=github.com/hashicorp/terraform-provider-azurerm/version.ProviderVersion=acc\"\n=== RUN   TestAccResourceGroupExample_basic\n=== PAUSE TestAccResourceGroupExample_basic\n=== CONT  TestAccResourceGroupExample_basic\n--- PASS: TestAccResourceGroupExample_basic (88.15s)\n=== RUN   TestAccResourceGroupExample_complete\n=== PAUSE TestAccResourceGroupExample_complete\n=== CONT  TestAccResourceGroupExample_complete\n--- PASS: TestAccResourceGroupExample_complete (120.23s)\n=== RUN   TestAccResourceGroupExample_requiresImport\n=== PAUSE TestAccResourceGroupExample_requiresImport\n=== CONT  TestAccResourceGroupExample_requiresImport\n--- PASS: TestAccResourceGroupExample_requiresImport (116.15s)\nPASS\nok      github.com/hashicorp/terraform-provider-azurerm/internal/services/resource  324.753s\n</code></pre>"},{"location":"topics/guide-new-resource/#step-8-add-documentation-for-this-resource","title":"Step 8: Add Documentation for this Resource","text":"<p>At this point in time documentation for each Resource (and Data Source) is written manually, located within the <code>./website</code> folder - in this case this will be located at <code>./website/docs/d/resource_group_example.html.markdown</code>.</p> <p>There is a tool within the repository to help scaffold the documentation for a Resource - the documentation for this Resource can be scaffolded via the following command:</p> <pre><code>$ make scaffold-website BRAND_NAME=\"Resource Group Example\" RESOURCE_NAME=\"azurerm_resource_group_example\" RESOURCE_TYPE=\"resource\" RESOURCE_ID=\"/subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/group1\"\n</code></pre> <p>The documentation should look something like below - containing both an example usage and the required, optional and computed fields:</p> <p>Note: In the example below you'll need to replace each <code>[]</code> with a backtick \"`\" - as otherwise this gets rendered incorrectly, unfortunately.</p> <pre><code>---\nsubcategory: \"Base\"\nlayout: \"azurerm\"\npage_title: \"Azure Resource Manager: azurerm_resource_group_example\"\ndescription: |-\n  Manages a Resource Group.\n---\n\n# azurerm_resource_group_example\n\nManages a Resource Group.\n\n## Example Usage\n\n[][][]hcl\nresource \"azurerm_resource_group_example\" \"example\" {\n  name     = \"example\"\n  location = \"West Europe\"\n}\n[][][]\n\n## Arguments Reference\n\nThe following arguments are supported:\n\n* `location` - (Required) The Azure Region where the Resource Group should exist. Changing this forces a new Resource Group to be created.\n\n* `name` - (Required) The Name which should be used for this Resource Group. Changing this forces a new Resource Group to be created.\n\n---\n\n* `tags` - (Optional) A mapping of tags which should be assigned to the Resource Group.\n\n## Attributes Reference\n\nIn addition to the Arguments listed above - the following Attributes are exported:\n\n* `id` - The ID of the Resource Group.\n\n## Timeouts\n\nThe `timeouts` block allows you to specify [timeouts](https://www.terraform.io/language/resources/syntax#operation-timeouts) for certain actions:\n\n* `create` - (Defaults to 30 minutes) Used when creating the Resource Group.\n* `read` - (Defaults to 5 minutes) Used when retrieving the Resource Group.\n* `update` - (Defaults to 30 minutes) Used when updating the Resource Group.\n* `delete` - (Defaults to 30 minutes) Used when deleting the Resource Group.\n\n## Import\n\nResource Groups can be imported using the `resource id`, e.g.\n\n[][][]shell\nterraform import azurerm_resource_group_example.example /subscriptions/00000000-0000-0000-0000-000000000000/resourceGroups/example\n[][][]\n</code></pre> <p>Note: In the example above you'll need to replace each <code>[]</code> with a backtick \"`\" - as otherwise this gets rendered incorrectly, unfortunately.</p>"},{"location":"topics/guide-new-resource/#step-9-send-the-pull-request","title":"Step 9: Send the Pull Request","text":"<p>See our recommendations for opening a Pull Request.</p>"},{"location":"topics/guide-new-service-package/","title":"Guide: New Service Package","text":"<p>There's a few steps involved in adding a new Service Package.</p> <ol> <li> <p>Create a new directory within <code>./internal/services</code> with the Service Name (see naming).</p> </li> <li> <p>Create an empty Client within the Service Package (<code>./internal/services/{name}/client/client.go</code>):</p> </li> </ol> <pre><code>package client\n\nimport (\n\"github.com/hashicorp/terraform-provider-azurerm/internal/common\"\n)\n\ntype Client struct {\n}\n\nfunc NewClient(o *common.ClientOptions) *Client {\nreturn &amp;Client{}\n}\n</code></pre> <ol> <li>Create an empty Registration within the Service Package (<code>./internal/services/{name}/registration.go</code>) which implements the <code>TypedServiceRegistration</code> interface:</li> </ol> <pre><code>package {name}\n\nimport (\n\"github.com/hashicorp/terraform-provider-azurerm/internal/sdk\"\n)\n\ntype Registration struct{}\n\nvar (\n_ sdk.TypedServiceRegistration = Registration{}\n)\n\nfunc (r Registration) DataSources() []sdk.DataSource {\nreturn []sdk.DataSource{}\n}\n\nfunc (r Registration) Resources() []sdk.Resource {\nreturn []sdk.Resource{}\n}\n\n// Name is the name of this Service\nfunc (r Registration) Name() string {\nreturn \"App Service\"\n}\n\n// WebsiteCategories returns a list of categories which can be used for the sidebar\nfunc (r Registration) WebsiteCategories() []string {\nreturn []string{\n\"App Service\",\n}\n}\n</code></pre> <ol> <li>Register the Service Registration.</li> <li>Define and Register the Client for this Service Package.</li> <li>Add this to the Client struct.</li> <li>Call the Register function.</li> <li>Re-run the generation to ensure the generated files are up to date (<code>make generate</code>).</li> </ol> <p>At this point the Service Package should be registered, and you can build a new Data Source or a new Resource as required.</p>"},{"location":"topics/guide-opening-a-pr/","title":"Opening a PR","text":"<p>Firstly all contributions are welcome!</p> <p>There is no change too small for us to accept and minor formatting, consistency and documentation PRs are very welcome! However, before making any large or structural changes it is recommended to seek feedback (preferably by reaching out in our community slack) to prevent wasted time and effort. We may already be working on a solution, or have a different direction we would like to take.</p> <p>If you are ever unsure please just reach out, we are more than happy to guide you in the right direction!</p>"},{"location":"topics/guide-opening-a-pr/#considerations","title":"Considerations","text":"<p>As a general rule, the smaller the PR the quicker it's merged - as such when upgrading an SDK and introducing new properties we'd ask that you split that into multiple smaller PR's, for example if you were planning on updating an SDK to add a new resource and update an existing one we would prefer <code>3</code> separate PRs:</p> <ol> <li>Update the Cosmos DB SDK to use API Version <code>2022-02-02</code> from <code>2020-01-01</code>.</li> <li>Add the new property <code>new_feature</code> to the <code>azurerm_cosmosdb_*</code> resources.</li> <li>Introduce the New Resource <code>azurerm_cosmosdb_resource</code>.</li> </ol> <p>We also recommend not opening a PR based on your <code>main</code> branch. By doing this any changed pushed to the PR may inadvertently be also pushed to your <code>main</code> branch without warning.</p> <p>Due to the high volume of PR's on the project and to ensure maintainers are able to focus on changes which are ready to review, please do not open Draft PRs or work that is not yet ready to be reviewed.</p>"},{"location":"topics/guide-opening-a-pr/#process","title":"Process","text":"<p>Pull Requests generally go through a number of phrases which vary slightly depending on what's being changed.</p> <p>The following guides cover the more common scenarios we see:</p> <ul> <li>Extending an existing Resource</li> <li>Extending an existing Data Source</li> <li>Adding a new Resource</li> <li>Adding a new Data Source</li> <li>Adding a new Service Package</li> </ul> <p>In general, Pull Requests which add/change either code or SDK's go through the following steps:</p> <ol> <li>Make / commit the changes.</li> <li>Run GitHub Actions linting and checks locally with the make command <code>make pr-check</code>.</li> <li>Run all relevant Acceptance Tests.</li> <li>Open a Pull Request (see below on <code>What makes a good PR?</code>).</li> <li>GitHub actions will trigger and run all linters.</li> <li>A Maintainer will review the PR and also run acceptance tests against our test subscription.</li> <li>Once all comments have been addressed and tests pass the PR will be merged</li> <li>The maintainer will update the CHANGELOG.md.</li> </ol>"},{"location":"topics/guide-opening-a-pr/#what-makes-a-good-pr","title":"What makes a good PR?","text":"<ul> <li>Don't send the PR from your <code>main</code> branch.</li> <li>The PR Title is obvious/clear about what it's changing (see <code>Title</code> below).</li> <li>The PR Body contains a summary of what/why is included (see <code>Body</code> below).</li> <li>any linked Issues</li> </ul>"},{"location":"topics/guide-opening-a-pr/#title","title":"Title","text":"<p>The title of the PR should clearly state what the PR is doing, and ideally should match the entry that will end up in the changelog.</p> <p>Examples of good PR titles:</p> <ul> <li><code>azurerm_storage_management_policy - Mark rule.filters.blob_type as required</code></li> <li><code>azurerm_container_registry - support updating replications on demand</code></li> <li><code>azurerm_automation_account - support for the encrytion, local_authentication_enabled, and tags properties</code></li> <li><code>Data Source: azurerm_automation_account - prevent panic (#15474) by adding a nil check</code></li> <li><code>Upgrade bot API version from 2021-03-01 to 2021-05-01-preview</code></li> <li><code>New Resource: azurerm_managed_disk_sas_token</code></li> <li><code>New Data Source: azurerm_managed_disk_sas_token</code></li> <li><code>Docs: Fix wrong command in 3.0-upgrade-guide</code></li> </ul> <p>Examples of poorly written PR titles:</p> <ul> <li><code>fix sql bug</code></li> <li><code>fixes #1234</code></li> <li><code>new resource</code></li> <li><code>upgrade sdk</code></li> <li><code>upgrade compute api</code></li> <li><code>add cosmos property</code></li> <li><code>support encryption, local_authentication_enabled properties</code></li> </ul>"},{"location":"topics/guide-opening-a-pr/#description","title":"Description","text":"<p>A PR should include a brief description of the reason for the PR, what it is doing, what it is trying to accomplish, and anything relevant for a reviewer to know. It also helps to paste the output from running the accpetance tests.</p> <p>It should also link to any related issues/PRs and include the following for any issues that it will resolve:</p> <pre><code>fixes #1234,#5678\n</code></pre>"},{"location":"topics/guide-state-migrations/","title":"Guide: State Migrations","text":"<p>State migrations come into play if a resource's implementation needs to change, this can happen for a number a reasons, such as the implementation being incorrect or the API that the resource interacts with changes.</p> <p>Common scenarios where a state migration would be required in Azure are: * To correct the format of a Resource ID, the most common example is updating the casing of a segment e.g. <code>/subscriptions/12345678-1234-9876-4563-123456789012/resourcegroups/resGroup1</code> -&gt; <code>/subscriptions/12345678-1234-9876-4563-123456789012/resourceGroups/resGroup1</code> * Updating the default value of a property in the schema * Recasting property values in the schema, unlike the scenario's above this also requires changes to the user's config, thus should only be in a major version release</p> <p>Note: State migrations are one-way by design meaning they're not backward compatible. Once they've been run you can no longer downgrade to an older version of the provider. Care should be taken when adding state migrations and thorough manual testing should be done. See the section on Testing below.</p>"},{"location":"topics/guide-state-migrations/#conventions-within-the-azurerm-provider","title":"Conventions within the AzureRM Provider","text":"<p>State migrations are service specific and are thus kept under a <code>migration</code> folder of a service e.g.</p> <pre><code>\u251c\u2500\u2500 compute\n\u2502   \u251c\u2500\u2500 client\n\u2502   \u251c\u2500\u2500 migration\n\u2502   \u2502   \u251c\u2500\u2500 managed_disk_v0_to_v1.go\n\u2502   \u251c\u2500\u2500 managed_disk_resource.go\n...\n</code></pre> <p>The migration file follows the naming convention of <code>[resourceName]_[initialVersion]_to_[finalVersion].go</code> e.g. <code>managed_disk_v0_to_v1.go</code></p>"},{"location":"topics/guide-state-migrations/#walkthrough-for-adding-a-state-migration","title":"Walkthrough for adding a state migration","text":"<p>We will step through an example on how to add a state migration for a made up resource, <code>capybara_resource.go</code> in the <code>animals</code> service, where one of the Resource ID segments has been cased incorrectly. The state migration will make the following modification: <code>/subscriptions/12345678-1234-9876-4563-123456789012/resourceGroups/resGroup1/Capybaras/capybara1</code> -&gt; <code>/subscriptions/12345678-1234-9876-4563-123456789012/resourceGroups/resGroup1/capybaras/capybara1</code></p> <ol> <li> <p>Create an empty file under the service's migration folder called <code>capybara_v0_to_v1.go</code> e.g. (e.g. <code>./internal/services/animals/migration/capybara_v0_to_v1.go</code>)</p> </li> <li> <p>The bare minimum required within the file is shown below. Regardless of what the state migration is modifying, <code>Schema()</code> and <code>UpgradeFunc()</code> must be specified since these are referenced by the resource. <pre><code>package migration\n\nimport (\n\"context\"\n\n\"github.com/hashicorp/terraform-provider-azurerm/internal/tf/pluginsdk\"\n)\n\ntype CapybaraV0ToV1 struct{}\n\nfunc (CapybaraV0ToV1) Schema() map[string]*pluginsdk.Schema {\nreturn map[string]*pluginsdk.Schema{\n// TODO implement me!\n}\n}\n\nfunc (CapybaraV0ToV1) UpgradeFunc() pluginsdk.StateUpgraderFunc {\nreturn func(ctx context.Context, rawState map[string]interface{}, meta interface{}) (map[string]interface{}, error) {\n// TODO implement me!\nreturn nil, nil\n}\n}\n</code></pre></p> </li> <li> <p>Copy over the schema for <code>capybara_resource.go</code>. If nothing in the schema is changing then this can be copied over 1:1, however you will want to go through and remove some property attributes that are not required.    The <code>Schema()</code> is a point-in-time reference to the Terraform Schema for this Resource at this point - and is used by Terraform to deserialize/serialize the object from the Terraform State. For this reason only a subset of attributes should be defined here (including <code>Type</code>, <code>Required</code>, <code>Optional</code>, <code>Computed</code> and <code>Elem</code> [for maps/lists/sets, including any custom hash functions]) - and the following attributes can be removed from the Schema:</p> </li> <li> <p>Default</p> </li> <li>ValidateFunc</li> <li>ForceNew</li> <li>MaxItems</li> <li>MinItems</li> <li>AtLeastOneOf</li> <li>ConflictsWith</li> <li>ExactlyOneOf</li> <li>RequiredWith</li> </ol> <p>Other caveats to look out for when copying the schema over are:    * in-lining any schema elements which are returned by functions    * removing any if/else logic within the Schema, in most cases this will be feature flags e.g. <code>features.FourPointOh()</code></p> <ol> <li> <p>Fill out the UpgradeFunc to update the Terraform State for this resource. Typically this involves parsing the old Resource ID case-insensitively and then setting the correct casing for the <code>id</code> field (which is what this example assumes) - however note that State Migrations aren't limited to the <code>id</code> field. The file should now look like this: <pre><code>package migration\n\nimport (\n\"context\"\n\"log\"\n\n\"github.com/hashicorp/go-azure-sdk/resource-manager/animals/2023-11-01/capybaras\"\n\"github.com/hashicorp/terraform-provider-azurerm/internal/tf/pluginsdk\"\n)\n\ntype CapybaraV0ToV1 struct{}\n\nfunc (s CapybaraV0ToV1) Schema() map[string]*pluginsdk.Schema {\nreturn map[string]*pluginsdk.Schema{\n\"name\": {\nType:     pluginsdk.TypeString,\nRequired: true,\n},\n\n\"cuteness\": {\nType:     pluginsdk.TypeInt,\nRequired: true,\n},\n\n\"pet_names\": {\nType:     pluginsdk.TypeList,\nOptional: true,\nElem: &amp;pluginsdk.Schema{\nType: pluginsdk.TypeString,\n},\n},\n}\n}\n\nfunc (s CapybaraV0ToV1) UpgradeFunc() pluginsdk.StateUpgraderFunc {\nreturn func(ctx context.Context, rawState map[string]interface{}, meta interface{}) (map[string]interface{}, error) {\noldId := rawState[\"id\"].(string)\nparsed, err := capybaras.ParseCapybaraIDInsensitively(oldId)\nif err != nil {\nreturn nil, err\n}\n\nnewId := parsed.ID()\nlog.Printf(\"[DEBUG] Updating ID from %q to %q\", oldId, newId)\nrawState[\"id\"] = newId\nreturn rawState, nil\n}\n}\n</code></pre></p> </li> <li> <p>Finally we hook the state migration up to the resource. For typed resources this looks like the following <pre><code>package animal\n\nimport (\n\"context\"\n\"fmt\"\n\"time\"\n\n\"github.com/hashicorp/go-azure-sdk/resource-manager/animals/2023-11-01/capybaras\"\n\"github.com/hashicorp/terraform-provider-azurerm/internal/sdk\"\n\"github.com/hashicorp/terraform-provider-azurerm/internal/services/animals/migration\"\n\"github.com/hashicorp/terraform-provider-azurerm/internal/tf/pluginsdk\"\n)\n\ntype CapybaraResource struct{}\n\nvar (\n_ sdk.ResourceWithStateMigration = CapybaraResource{}\n)\n\ntype CapybaraResourceModel struct {\nName       string   `tfschema:\"name\"`\nCuteness   string   `tfschema:\"cuteness\"`\nPetNames   []string `tfschema:\"pet_names\"`\n\n}\n\nfunc (r CapybaraResource) StateUpgraders() sdk.StateUpgradeData {\nreturn sdk.StateUpgradeData{\nSchemaVersion: 1, // This field references the version which the state migration updates the schema to i.e. v0 -&gt; v1\nUpgraders: map[int]pluginsdk.StateUpgrade{\n0: migration.CapybaraV0ToV1{},\n},\n}\n}\n\n// The rest of the resource e.g. Create/Update/Read/Delete methods have been omitted for brevity\n</code></pre></p> </li> </ol>"},{"location":"topics/guide-state-migrations/#testing","title":"Testing","text":"<p>Currently no automated testing for state migrations exist since the testing framework is unable to run different versions of the provider simultaneously. As a result testing for state migrations must be done manually and usually involves the following high level steps:</p> <ol> <li>Create the resource using an older version of the provider</li> <li>Locally build a version of the provider containing the state migration</li> <li>Enable development overrides for Terraform</li> <li>Run <code>terraform plan</code> and/or <code>terraform apply</code> using the locally built version of the provider</li> <li>Verify that there are no plan differences</li> </ol>"},{"location":"topics/high-level-overview/","title":"High Level Overview","text":"<p>The AzureRM Provider is a Plugin which is invoked by Terraform (Core) and comprised of Data Sources and Resources.</p> <p>Within the AzureRM Provider, these Data Sources and Resources are grouped into Service Packages - which are logical groupings of Data Sources/Resources based on the Azure Service they're related to.</p> <p>Each of these Data Sources and Resources has both Acceptance Tests and Documentation associated with each Data Source/Resource - the Acceptance Tests are also located within this Service Package, however the Documentation exists within a dedicated folder.</p>"},{"location":"topics/high-level-overview/#project-structure","title":"Project Structure","text":"<p>The Azure Provider is a large codebase which has evolved over time - but tends to follow consistent patterns for the most-part.</p> <p>The Provider is split up into Service Packages (see terminology) - with some other logic sprinkled across several packages.</p> <p>At a high-level, the Provider structure is:</p> <ul> <li><code>./examples</code><ul> <li>Contains more complete example usages of Data Sources and Resources offered by this Provider.</li> </ul> </li> <li><code>./helpers</code><ul> <li>This package is deprecated (and so intentionally not documented) - new functionality should instead be added to either the Service Package or go-azure-helpers.</li> </ul> </li> <li><code>./internal</code><ul> <li><code>./internal/acceptance</code><ul> <li>Contains the Acceptance Test wrappers that we use in the Azure Provider, offering common patterns across the Provider to be reused.</li> </ul> </li> <li><code>./internal/clients</code><ul> <li>Contains a reference to the Client from each Service Package, which is used in Data Sources and Resources to access the Azure API\u2019s.</li> </ul> </li> <li><code>./internal/common</code><ul> <li>Contains helper functions for registering Clients (for example, setting the user agent, configuring credentials etc).</li> </ul> </li> <li><code>./internal/features</code><ul> <li>Contains Feature Toggles for Provider functionality and behaviour (for example, enabling Betas or changing a resource type's soft delete or purge protection). This also contains the struct and parsing of/default values for the <code>features</code> block (within the Provider block).</li> </ul> </li> <li><code>./internal/locks</code><ul> <li>Provides common locking across resources where necessary to workaround API consistency issues.</li> </ul> </li> <li><code>./internal/provider</code><ul> <li>Contains the Provider implementation itself, the Provider schema and a reference to each Service Registration so that Data Sources and Resources can be surfaced within the Provider.</li> </ul> </li> <li><code>./internal/resourceid</code><ul> <li>This package is deprecated in favour of <code>github.com/hashicorp/go-azure-helpers/resourcemanager/resourceids</code> and will be removed in the future.</li> </ul> </li> <li><code>./internal/resourceproviders</code><ul> <li>Contains the list of Resource Providers which should be auto-registered by the Provider.</li> </ul> </li> <li><code>./internal/sdk</code><ul> <li>Contains the Typed Plugin SDK functionality used in this Provider.</li> </ul> </li> <li><code>./internal/services</code><ul> <li>Contains a packages for each service that the provider supports  (e.g. <code>appconfiguration</code>, <code>compute</code>) in which are each's Data Sources and Resources.</li> </ul> </li> <li><code>./internal/tags</code><ul> <li>Contains helpers for parsing Tags from the Terraform Configuration and setting Tags into the Terraform State.</li> </ul> </li> <li><code>./internal/tf</code><ul> <li>Contains helpers and abstractions on top of the Terraform Plugin SDK.</li> </ul> </li> <li><code>./internal/timeouts</code><ul> <li>Contains helpers for computing the Timeouts for a Data Source / Resource - used in Untyped Data Sources and Untyped Resources.</li> </ul> </li> <li><code>./internal/tools</code><ul> <li>This package contains tooling used to generate functionality within the Provider, for example for Resource ID\u2019s and Website Documentation.</li> </ul> </li> </ul> </li> <li><code>./scripts</code><ul> <li>Contains various scripts used during testing, linting, and building the provider.</li> </ul> </li> <li><code>./utils</code><ul> <li>This primarily contains helper functions for converting simple types (e.g. bool/int/strings) to pointers (e.g. <code>utils.String(\u201csomeValue\u201d)</code>.</li> <li>We intend to deprecate this folder in time and new functionality should be added to individual service packages where possible. The existing functions will be gradually moved (via aliasing) into another repository.</li> </ul> </li> <li><code>./vendor</code><ul> <li>Contains the vendored copies of the go modules the provider uses. For more information please refer to the official Go Documentation.</li> </ul> </li> <li><code>./website</code><ul> <li>Contains the guides and documentation for each resource (in <code>./website/docs/r</code>) and data source (in <code>./website/docs/d</code>) that are published to the Terraform registry.</li> </ul> </li> </ul> <p>Note: Due to the size of the codebase and open Pull Requests - when functionality is moved we use aliasing to try and avoid breaking open Pull Requests / big-bang migrations. These aliases stick around for a few weeks to allow open PR\u2019s to be merged without extra out of scope changes - at which point these aliases are removed.</p> <p>Each Service Package consists of (to take <code>appconfiguration</code> as an example):</p> <ul> <li><code>./internal/services/appconfiguration</code><ul> <li><code>./client</code><ul> <li>Contains a Client struct, with a reference to any SDK Clients used to access the Azure API\u2019s within this Service Package.</li> </ul> </li> <li><code>./parse</code><ul> <li>Contains Resource ID Formatters and Parsers.</li> </ul> </li> <li><code>./validate</code><ul> <li>Contains Validation functions for this Service Package, including Resource ID Validators.</li> </ul> </li> <li><code>./app_configuration_data_source.go</code> - the Data Source <code>azurerm_app_configuration</code></li> <li><code>./app_configuration_data_source_test.go</code> - Acceptance tests for the Data Source <code>azurerm_app_configuration</code></li> <li><code>./app_configuration_key_resource.go</code> - the Resource <code>azurerm_app_configuration_key</code></li> <li><code>./app_configuration_key_resource_test.go</code> - Acceptance Tests for the Resource <code>azurerm_app_configuration_key</code></li> <li><code>./app_configuration_resource.go</code> - the Resource <code>azurerm_app_configuration</code></li> <li><code>./app_configuration_resource_test.go</code> - Acceptance tests for the Resource <code>azurerm_app_configuration</code></li> <li><code>./registration.go</code> - the Service Registration for this Service Package</li> </ul> </li> </ul> <p>Some Service Packages may also contain:</p> <ul> <li><code>./migration</code> - any State Migrations used in Resources.</li> <li><code>./sdk</code> - any Embedded SDK\u2019s used to access the Azure API\u2019s (either Resource Manager or Data Plane).</li> <li><code>./resourceids.go</code> - used to generate Resource ID Formatters, Parsers and Validators.</li> </ul> <p>\u2014-</p> <ul> <li>Data Sources use the filename format: <code>{name}_data_source.go</code></li> <li>Acceptance Tests for Data Sources use the filename format: <code>{name}_data_source_test.go</code> (note: Golang requires that Tests are contained within a <code>test.go</code> file)</li> <li>Resources use the filename format: <code>{name}_resource.go</code></li> <li>Acceptance Tests for Resources use the filename format: <code>{name}_resource_test.go</code> (note: Golang requires that Tests are contained within a <code>test.go</code> file)</li> </ul> <p>Note: there are a handful of exceptions to these to reduce stuttering (e.g. Resource Provider Registration Resource)</p>"},{"location":"topics/high-level-overview/#types-of-data-sourcesresources-within-the-provider","title":"Types of Data Sources/Resources within the Provider","text":"<p>Whilst the Azure Provider is built on-top of the Terraform Plugin SDK - as this is a large codebase with a number of behavioural similarities across the Provider, we've added an abstraction atop the Terraform Plugin SDK to make development easier.</p> <p>This means that at this point in time, there are four types of Data Source/Resources which can be added in this Provider:</p> <ol> <li>(Untyped) Data Sources (based on the Terraform Plugin SDK) (example)).</li> <li>(Untyped) Resources (based on the Terraform Plugin SDK) (example)).</li> <li>Typed Data Sources (based on top of the Typed SDK within this Repository) (example)).</li> <li>Typed Resources (based on top of the Typed SDK within this Repository) (example)).</li> </ol> <p>At this point in time the codebase uses a mixture of both (primarily the Untyped Data Sources/Resources) - in time we plan to migrate across to using Typed Data Sources/Resources instead.</p> <p>Ultimately this approach will allow us to switch from using the Terraform Plugin SDK to Terraform Plugin Framework, enabling us to fix a number of long-standing issues in the Provider - whilst reducing the TLOC needed for each resource.</p>"},{"location":"topics/high-level-overview/#interaction-with-azure","title":"Interaction with Azure","text":"<p>This Provider makes use of a number of SDKs to interact with both the Azure Resource Manager and a number of associated Data Plane APIs, these are:</p> <ul> <li>go-azure-sdk - an opinionated Go SDK generated by Hashicorp for interaction with Azure Resource Manager</li> <li>The Azure SDK for Go - for interaction with Azure Resource Manager (generated from the Swagger files within the Azure/azure-rest-api-specs repository).</li> <li>Hamilton - for interaction with Microsoft Graph - and obtaining an authentication token using MSAL.</li> <li>Giovanni - for interaction with the Azure Storage Data Plane APIs.</li> </ul> <p>There's also a number of Embedded SDKs within the provider for interaction with Resource Manager Services which are not supported by the Azure SDK for Go - generated from the Swagger files within the Azure/azure-rest-api-specs repository.</p> <p>At this point in time, each of the SDKs mentioned above (excluding Hamilton) make use of Azure/go-autorest as a base layer (e.g. for sending requests/responses/handling retries from Azure).</p>"},{"location":"topics/high-level-overview/#testing-the-provider","title":"Testing the Provider","text":"<p>Since the behaviour of the Azure API can change over time, the Provider leans on Acceptance Tests over Unit Tests for asserting that the Data Sources and Resources within the Provider work as expected.</p> <p>More details and guidance on how to test Data Sources/Resources can be found in the Acceptance Testing reference.</p>"},{"location":"topics/maintainer-changelog/","title":"Maintainer Specific: Updating the Changelog","text":"<p>Note: When sending a Pull Request you should not include a changelog entry as a part of the Pull Request - this is to avoid conflicts. Contributors should not be concerned with updating the changelog as that is something only maintainers will do during merge.</p> <p>When a PR is merged it may or may not be included in the changelog. While most PRs deserve a changelog entry not every change should be included in the changelog as some have no user facing impact. Some examples of PRs that should not be included are:</p> <ul> <li>unit and acceptance test fixes</li> <li>refactoring</li> <li>documentation changes</li> </ul> <p>Otherwise, every PR that affects users should be added to the appropriate section:</p> <ul> <li><code>FEATURES</code> - new resources and data sources</li> <li><code>ENHANCEMENTS</code> - new properties, functionality, and features (including SDK/API upgrades)</li> <li><code>BUG FIXES</code> - bug fixes</li> </ul> <p>When adding a changelog entry the following rules should be followed:</p> <ul> <li>be consistent! follow the formatting and language of the surrounding entries.</li> <li>entries should start with a lower case, not end in a period, and always use the serial (oxford) comma.</li> <li>each resource affected should be listed in full, i.e. do not use something like <code>azurerm_cosmosdb_*</code>.</li> <li>each entry should link to the pull request with the placeholder <code>[GH-{number}]</code> (e.g. <code>[GH-1234]</code>), this will be replaced with a link during the release process.</li> <li>entries should read as complete sentences such as <code>support for the property ```new_feature```</code> or <code>improve validation of the property ```old_feature```</code> not <code>support ```new_feature```</code>.</li> </ul> <p>And finally when making the edit commit, the PR number should be included in the commit message so the edit is linked to the PR, and the entry from the pr. For example <code>CHANGELOG.md for #1234</code>.</p> <p>Here is a list of common changelog entries and how they should be formatted:</p> <pre><code># X.YY.0 (Unreleased)\n\nFEATURES:\n\n* **New Data Source**: `azurerm_data_source` [GH-12345]\n* **New Resource**: `azurerm_resource` [GH-12345]\n\nENHANCEMENTS:\n\n* dependencies: updating to `v63.4.0` of `github.com/Azure/azure-sdk-for-go` [GH-12345]\n* dependencies: updating `api` to `2021-12-01` [GH-12345]\n* Data Source: `azurerm_data_source` - export the `value` attribute [GH-12345]\n* `azurerm_resource` - the `sku` property can now be updated to `Basic` or `Standard` without recreating the resource [GH-12345]\n* `azurerm_resource` - support for the `thing1` property [GH-12345]\n* `azurerm_resource` - support for the `thing2`, `thing3`, and `thing4` properties [GH-12345]\n* `azurerm_resource` - improve validation for the `timeout` property within the `termination_notification` block [GH-12345]\n\nBUG FIXES:\n\n* Data Source: `azurerm_data_source` - prevent a possible crash by setting `queue_name` correctly [GH-12345]\n* Data Source: `azurerm_data_source` - correctly populate the `kind` and `os_type` attributes [GH-12345]\n* `azurerm_data_factory_dataset_delimited_text` - set defaults properly for `column_delimiter`, `quote_character`, `escape_character`, `first_row_as_header`, and `null_value` [GH-12345]\n* `azurerm_linux_function_app` - correctly deduplicate user `app_settings` [GH-12345]\n* `azurerm_windows_function_app_slot` - correctly deduplicate user `app_settings` [GH-12345]\n</code></pre>"},{"location":"topics/reference-acceptance-testing/","title":"Acceptance Testing","text":"<p>Acceptance tests are an essential part of the provider - they provide confidence in the functionality and consistency of resources and data sources as they are introduced and over time.</p> <p>Whilst we can't test every use-case or permutation of fields - each data source/resource gets a common set of tests to ensure the core use-cases are covered.</p> <p>As a general rule, the more complex the resource the more tests there are - for example AKS, App Service and Virtual Machines all have a large number of end-to-end tests.</p>"},{"location":"topics/reference-acceptance-testing/#considerations","title":"Considerations","text":"<p>Note: Acceptance Tests provision real resources within Azure - which may have an associated charge for each resource.</p> <p>When selecting SKUs for testing, pick the lowest/cheapest SKU which covers the test - unless there's good reason to otherwise (e.g. some configurations can provision more quickly using one SKU over another).</p>"},{"location":"topics/reference-acceptance-testing/#running-the-tests","title":"Running the Tests","text":"<p>See Running the Tests.</p>"},{"location":"topics/reference-acceptance-testing/#test-package","title":"Test Package","text":"<p>While tests reside in the same folder as resource and data source .go files, they need to be in a separate test package to prevent circuler references. ie for the file <code>./internal/services/aab2c/aadb2c_directory_data_source_test.go</code> the package should be:</p> <pre><code>package aadb2c_test\n\nimport ...\n</code></pre> <p>This is checked by <code>make test</code> during CI.</p>"},{"location":"topics/reference-acceptance-testing/#import-step","title":"Import Step","text":"<p>During acceptance tests it is important to validate that the resource in Azure matches what Terraform expects and has saved into state. This can be done by adding a <code>data.ImportStep()</code> after every step. This will import the resource into Terraform and compare that the Terraform state matches the Azure Resource.</p> <p>As some properties (such as sensitive data like passwords) are not returned from Azure you can ignore these properties by passing them into the import step: <code>data.ImportStep(\"password\", \"database_primary_key\")</code>.</p>"},{"location":"topics/reference-acceptance-testing/#naming","title":"Naming","text":"<p>Test names should follow the convention <code>TestAcc</code> + <code>ResourceName</code> + <code>_</code> + <code>test</code> -&gt; <code>TestAccExampleResource_basic</code>, or to group tests:</p> <pre><code>func TestAccExampleResource_category_test1(t *testing.T) { ... }\nfunc TestAccExampleResource_category_test2(t *testing.T) { ... }\n</code></pre>"},{"location":"topics/reference-acceptance-testing/#acceptance-tests","title":"Acceptance Tests","text":"<p>The Acceptance Tests for both Data Sources and Resources within this Provider use a Go struct for each test, in the form <code>{Name}{DataSource|Resource}Test</code>, for example:</p> <pre><code>// for a data source named Example:\ntype ExampleDataSourceTest struct {}\n\n// for a resource named Example:\ntype ExampleResourceTest struct {}\n</code></pre> <p>This allows the test configurations to be scoped (and not used unintentionally across different resources), for example a Resource may use:</p> <pre><code>type ExampleResourceTest struct {}\n\nfunc (ExampleResourceTest) basic(data acceptance.TestData) string {\nreturn fmt.Sprintf(`\nprovider \"azurerm\" {\n  features {}\n}\n\nresource \"azurerm_example_resource\" \"example\" {\n  name             = \"my_example_resource\"\n  location         = \"%s\"\n  example_property = \"bar\"\n}\n\n`, data.Locations.Primary)\n}\n</code></pre> <p>This allows the Acceptance Test for each Data Source/Resource to reference that struct and obtain the associated Terraform Configuration as a part of the test e.g.:</p> <pre><code>func TestAccExampleResource_basic(t *testing.T) {\ndata := acceptance.BuildTestData(t, \"azurerm_example_resource\", \"test\")\nr := ExampleResourceTest{}\n\ndata.ResourceTest(t, r, []acceptance.TestStep{\n{\nConfig: r.basic(data),\nCheck: acceptance.ComposeTestCheckFunc(\ncheck.That(data.ResourceName).ExistsInAzure(r),\n),\n},\ndata.ImportStep(),\n})\n}\n</code></pre>"},{"location":"topics/reference-acceptance-testing/#which-tests-are-required","title":"Which Tests are Required?","text":"<p>At a minimum, a Data Source requires:</p> <ul> <li>A <code>basic</code> test (Example) - this tests the minimum fields (e.g. all Required fields) for this Data Source.</li> </ul> <p>However more complex Data Sources can warrant additional acceptance tests - consideration should be given during the development of each Data Source to what's important to be tested.</p> <p>At a minimum, a Resource requires:</p> <ul> <li> <p>A <code>basic</code> test (Example) - this tests the minimum fields (e.g. all Required fields) for this Resource.</p> </li> <li> <p>A <code>requiresImport</code> test (Example) - this test exercises the logic in the <code>create</code> function of a resource that checks for the prior existence of the resource and being created and expects an error. The acceptance test package provides a helper function is provided to be used in the test, called <code>RequiresImportErrorStep</code> for this purpose.</p> </li> <li> <p>A <code>complete</code> test (Example) - this tests all possible fields (e.g. all Required/Optional fields) for this Resource.</p> </li> <li> <p>A <code>update</code> test (Example) - This test exercises a change of values for any properties that can be updated by executing consecutive configurations to change a resource in a predictable manner. Properties which are <code>ForceNew</code> should not be tested in this way.</p> </li> </ul> <p>However more complex Resource generally warrant additional acceptance tests - consideration should be given during the development of each Resource to what's important to be tested.</p>"},{"location":"topics/reference-acceptance-testing/#example-data-source-basic","title":"Example - Data Source - Basic","text":"<p>A Data Source generally has one or two Required properties and a number of Computed properties - as such it's typical for this test to reuse the Terraform Configuration from the <code>Complete</code> test for the associated Resource (as this exercises all options on the resource).</p> <p>Since the Data Source primarily exposes Computed-only fields which aren't specified in the Terraform Configuration, we typically assert that these computed fields have a/an expected value - which differs from the Acceptance Tests for the Resource where we'll use an Import step to confirm that the Terraform Configuration matches the imported state.</p> <pre><code>func TestAccExampleDataSource_complete(t *testing.T) {\ndata := acceptance.BuildTestData(t, \"data.azurerm_example_resource\", \"test\")\nr := ExampleDataSourceTest{}\n\ndata.ResourceTest(t, r, []acceptance.TestStep{\n{\nConfig: r.complete(data),\nCheck: acceptance.ComposeTestCheckFunc(\ncheck.That(data.ResourceName).Key(\"example_property\").HasValue(\"bar\")\ncheck.That(data.ResourceName).Key(\"example_optional_bool\").HasValue(\"false\")\ncheck.That(data.ResourceName).Key(\"example_optional_string\").HasValue(\"foo\")\n),\n},\n})\n}\n\nfunc (ExampleDataSourceTest) complete(data acceptance.TestData) string {\ntemplate := ExampleResourceTest{}.basic(data)\nreturn fmt.Sprintf(`\n%[1]s\n\ndata \"azurerm_example_resource\" \"test\" {\n  name = azurerm_example_resource.test.name\n}\n`, template)\n}\n</code></pre>"},{"location":"topics/reference-acceptance-testing/#example-resource-basic","title":"Example - Resource - Basic","text":"<p>This test provisions the resource using the minimum configuration possible (e.g. only the <code>Required</code> fields), which is intended to test the happy path (of creating, reading and then destroying a resource).</p> <p>As we're testing the Resource, we make use of an <code>ImportStep</code> as a part of the Acceptance Test to ensure that each of the fields specified as a part of the Terraform Configuration are set into the state.</p> <pre><code>func TestAccExampleResource_basic(t *testing.T) {\ndata := acceptance.BuildTestData(t, \"azurerm_example_resource\", \"test\")\nr := ExampleResourceTest{}\n\ndata.ResourceTest(t, r, []acceptance.TestStep{\n{\nConfig: r.basic(data),\nCheck: acceptance.ComposeTestCheckFunc(\ncheck.That(data.ResourceName).ExistsInAzure(r),\n),\n},\ndata.ImportStep(),\n})\n}\n\nfunc (ExampleResourceTest) basic(data acceptance.TestData) string {\nreturn fmt.Sprintf(`\nprovider \"azurerm\" {\n  features {}\n}\n\nresource \"azurerm_example_resource\" \"example\" {\n  name             = \"my_example_resource\"\n  location         = \"%s\"\n  example_property = \"bar\"\n}\n`, data.Locations.Primary)\n}\n</code></pre>"},{"location":"topics/reference-acceptance-testing/#example-resource-complete","title":"Example - Resource - Complete","text":"<p>This test provisions the resource using the maximum configuration possible (e.g. all <code>Required</code> and <code>Optional</code> fields which can be set together), which is intended to test the more complex scenario for this resource.</p> <p>As we're testing the Resource, we make use of an <code>ImportStep</code> as a part of the Acceptance Test to ensure that each of the fields specified as a part of the Terraform Configuration are set into the state.</p> <pre><code>func TestAccExampleResource_complete(t *testing.T) {\ndata := acceptance.BuildTestData(t, \"azurerm_example_resource\", \"test\")\nr := ExampleResourceTest{}\n\ndata.ResourceTest(t, r, []acceptance.TestStep{\n{\nConfig: r.complete(data),\nCheck: acceptance.ComposeTestCheckFunc(\ncheck.That(data.ResourceName).ExistsInAzure(r),\n),\n},\ndata.ImportStep(),\n})\n}\n\nfunc (ExampleResourceTest) complete(data acceptance.TestData) string {\nreturn fmt.Sprintf(`\nprovider \"azurerm\" {\n  features {}\n}\n\nresource \"azurerm_example_resource\" \"example\" {\n  name             = \"my_example_resource\"\n  location         = \"%s\"\n  example_property = \"bar\"\n\n  example_optional_bool   = false\n  example_optional_string = \"foo\"\n\n  tags = {\n    \"Hello\" = \"World\"\n  }\n}\n\n`, data.Locations.Primary)\n}\n</code></pre>"},{"location":"topics/reference-acceptance-testing/#example-resource-requires-import","title":"Example - Resource - Requires Import","text":"<p>This test is intended to confirm that the logic within the create function (to check for the presence of an existing resource) works as intended - as the Azure Resource Manager API's are Upserts, meaning that without this check it's possible to unintentionally \"adopt\" existing resources.</p> <p>Since this test is attempting to provision the same resource, with the same identifier, twice - this test typically reuses the <code>Basic</code> test as a part of it - interpolating it's values as required.</p> <pre><code>func TestAccExampleResource_basic(t *testing.T) {\ndata := acceptance.BuildTestData(t, \"azurerm_example_resource\", \"test\")\nr := ExampleResourceTest{}\n\ndata.ResourceTest(t, r, []acceptance.TestStep{\n{\nConfig: r.basic(data),\nCheck: acceptance.ComposeTestCheckFunc(\ncheck.That(data.ResourceName).ExistsInAzure(r),\n),\n},\ndata.RequiresImportErrorStep(r.requiresImport),\n})\n}\n\nfunc (r ExampleResourceTest) requiresImport(data acceptance.TestData) string {\ntemplate := r.basic(data)  return fmt.Sprintf(`\n%[1]s\n\nresource \"azurerm_example_resource\" \"import\" {\n  name             = azurerm_example_resource.example.name\n  location         = azurerm_example_resource.example.location\n  example_property = azurerm_example_resource.example.example_property\n}\n`, template)\n}\n</code></pre>"},{"location":"topics/reference-acceptance-testing/#example-resource-update","title":"Example - Resource - Update","text":"<p>This test is used to confirm that the <code>Update</code> function of the Resource works - as such only <code>Required</code>/<code>Optional</code> fields which are not <code>ForceNew</code> can be updated.</p> <p>The bare-minimum example for this is provisioning the <code>basic</code> configuration and then updating it using the <code>complete</code> test configuration above, for example:</p> <pre><code>func TestAccExampleResource_update(t *testing.T) {\ndata := acceptance.BuildTestData(t, \"azurerm_example_resource\", \"test\")\nr := ExampleResourceTest{}\n\ndata.ResourceTest(t, r, []acceptance.TestStep{\n{   // first provision the resource\nConfig: r.basic(data),\nCheck: acceptance.ComposeTestCheckFunc(\ncheck.That(data.ResourceName).ExistsInAzure(r),\n),\n},\ndata.ImportStep(),\n{   // then perform the update\nConfig: r.complete(data),\nCheck: acceptance.ComposeTestCheckFunc(\ncheck.That(data.ResourceName).ExistsInAzure(r),\n),\n},\ndata.ImportStep(),\n})\n}\n</code></pre> <p>However this doesn't necessarily cover all of the use-cases for this resource - or may be too broad depending on the resource, as such it's also common to have tests covering a subset of the fields, for example:</p> <p>Note: This is a simplified example for testing purposes, we'd generally recommend a test covering a related subset of the resource (e.g. enabling/disabling a block within the resource), rather than a single field - but it depends on the resource.</p> <pre><code>func TestAccExampleResource_someSetting(t *testing.T) {\ndata := acceptance.BuildTestData(t, \"azurerm_example_resource\", \"test\")\nr := ExampleResourceTest{}\n\ndata.ResourceTest(t, r, []acceptance.TestStep{\n{   // first provision the resource\nConfig: r.someSetting(data, true),\nCheck: acceptance.ComposeTestCheckFunc(\ncheck.That(data.ResourceName).ExistsInAzure(r),\n),\n},\ndata.ImportStep(),\n{   // then perform the update to disable this setting\nConfig: r.someSetting(data, false),\nCheck: acceptance.ComposeTestCheckFunc(\ncheck.That(data.ResourceName).ExistsInAzure(r),\n),\n},\ndata.ImportStep(),\n{   // finally, check we can re-enable this once it's been disabled\nConfig: r.someSetting(data, true),\nCheck: acceptance.ComposeTestCheckFunc(\ncheck.That(data.ResourceName).ExistsInAzure(r),\n),\n},\ndata.ImportStep(),\n})\n}\n\nfunc (ExampleResourceTest) someSettingEnabled(data acceptance.TestData) string {\nreturn fmt.Sprintf(`\nprovider \"azurerm\" {\n  features {}\n}\n\nresource \"azurerm_example_resource\" \"example\" {\n  name                 = \"my_example_resource\"\n  location             = \"%s\"\n}\n`, data.Locations.Primary)\n}\n</code></pre>"},{"location":"topics/reference-errors/","title":"Working with Errors","text":"<p>Following typical Go conventions, error variables within the AzureRM Provider codebase should be named <code>err</code>, e.g.</p> <pre><code>err := someMethodWhichReturnsAnError(...)\n</code></pre> <p>.. or in the case of a method which returns multiple return types:</p> <pre><code>model, err := someMethodWhichReturnsAnObjectAndAnError(...)\n</code></pre> <p>These errors should also be wrapped with more context:</p> <pre><code>func doSomething() error {\nerr := doSomethingWhichCanError()\nif err != nil {\nreturn fmt.Errorf(\"performing somethingWhichCanError: %+v\", err)\n}\nreturn nil\n}\n</code></pre> <p>Since this method only returns an error, we can instead reduce this to:</p> <pre><code>if err := doSomethingWhichCanError(); err != nil {\nreturn fmt.Errorf(\"performing somethingWhichCanError: %+v\", err)\n}\nreturn nil\n</code></pre> <p>Note that when calling code from within a Terraform Data Source/Resource, the Resource ID type (note: not the raw Resource ID) can be used as a formatting argument, for example:</p> <pre><code>id := someResource.NewResourceGroupID(\"subscription-id\", \"my-resource-group\")\nreturn fmt.Errorf(\"deleting %s: %+v\", id, err)\n</code></pre> <p>which will output:</p> <pre><code>deleting Resource Group \"my-resource-group\" (Subscription ID \"subscription-id\"): some error\"\n</code></pre> <p>When parsing existing Resource IDs it is sufficient to return the error as is since all the parsing functions return standardised and descriptive error messages:</p> <pre><code>id, err := someResource.ParseResourceID(state.ID)\nif err != nil {\nreturn err\n}\n</code></pre>"},{"location":"topics/reference-errors/#internal-errors","title":"Internal Errors","text":"<p>Internal errors, which are entirely outside the users control (such as failed expectations) that occur within the provider should be prefixed with <code>internal-error</code>, for example:</p> <pre><code>deadline, ok := ctx.Deadline()\nif !ok {\nreturn fmt.Errorf(\"internal-error: context had no deadline\")\n}\n</code></pre>"},{"location":"topics/reference-errors/#notes","title":"Notes","text":"<p>Error messages should be both short and clear, using the context as relevant - for example use:</p> <ul> <li><code>return fmt.Errorf(\"updating %s: %+v\", id, err)</code></li> <li><code>return fmt.Errorf(\"waiting for %s to finish provisioning: %+v\", id, err)</code></li> <li><code>return fmt.Errorf(\"waiting for %s to finish updating: %+v\", id, err)</code></li> </ul> <p>instead of:</p> <ul> <li><code>return err</code></li> <li><code>return fmt.Errorf(\"failed updating thing: %+v\", err)</code></li> <li><code>return fmt.Errorf(\"something went wrong: %+v\", err)</code></li> </ul> <p>This type of error wrapping should be applied to all error handling including any nested function that contains two or more error checks (e.g., a function that calls an update API and waits for the update to finish or builds an SDK struct) so practitioners and code maintainers have a clear idea which generated the error.</p> <p>NOTE: Wrapped error messages should generally not start with <code>failed</code>, <code>error</code>, or an uppercase letter as there will a function higher up the stack that will prefix this.</p> <p>When returning errors in those situations, it is important to consider the calling context and to exclude any information the calling function is likely to include, while including any additional context then calling function may not have.</p>"},{"location":"topics/reference-glossary/","title":"Glossary","text":"<p>This document contains a summary of the terminology used within the Azure Provider.</p>"},{"location":"topics/reference-glossary/#azure-resource-id","title":"Azure Resource ID","text":"<p>An Azure Resource ID is used to uniquely identify this Resource within Azure - in almost all cases this is a Path of Key-Value Pairs, for example:</p> <p>/subscriptions/11112222-3333-4444-555566667777/resourceGroups/myGroup</p> <p>Contains the Key-Value pairs:</p> <p><code>subscriptions</code>: <code>11112222-3333-4444-555566667777</code> <code>resourceGroups</code>: <code>myGroup</code></p> <p>As the Azure Resource ID is comprised of user-specified Key-Value Pairs, the Azure Resource ID is predictable.</p>"},{"location":"topics/reference-glossary/#data-plane-api","title":"Data Plane API","text":"<p>A Data Plane API provides access to data for resources provisioned via the Resource Manager API. Some examples:</p> <ul> <li>The App Configuration Data Plane API allows for managing Keys and Features within an App Configuration.</li> <li>The Storage Data Plane API allows for the uploading/downloading of Blobs within a Storage Container (within a Storage Account).</li> </ul>"},{"location":"topics/reference-glossary/#embedded-sdk","title":"Embedded SDK","text":"<p>An Embedded SDK is an SDK that has been added directly into the providers code base (usually into <code>services/{name}/sdk</code>) rather than using go modules and vendoring it into <code>/vendor</code>.</p> <p>Whilst we generally vendor SDKs instead, we have a number of SDKs which aren't available elsewhere and are instead vendored into the codebase (see High Level Overview for more information).</p>"},{"location":"topics/reference-glossary/#resource-id-formatter","title":"Resource ID Formatter","text":"<p>A Resource ID Formatter is a Resource ID Struct which implements the <code>ID()</code> method - returning the (Azure) Resource ID as a string - which must be parseable using the associated Resource ID Parser.</p> <p>These are generally (but not always) auto-generated - see Terraform Managed Resource ID\u2019s below for more information.</p>"},{"location":"topics/reference-glossary/#resource-id-parser","title":"Resource ID Parser","text":"<p>A Resource ID Parser parses an (Azure) Resource ID into a Resource ID Struct - generally case-sensitively (since both Terraform Core and some downstream Azure API\u2019s are case sensitive), but optionally case-insensitively where required.</p> <p>These are generally (but not always) auto-generated - see Terraform Managed Resource ID\u2019s below for more information.</p>"},{"location":"topics/reference-glossary/#resource-id-struct","title":"Resource ID Struct","text":"<p>A Resource ID Struct is a Golang Struct defining the user-specifiable values within an (Azure) Resource ID. For example, in the case of a Resource Group ID that would be the Subscription ID and Resource Group name.</p> <p>A Resource ID Struct should have an associated Resource ID Formatter, Parser and (optionally) Validator.</p> <p>These are generally (but not always) auto-generated - see Terraform Managed Resource ID\u2019s below for more information.</p>"},{"location":"topics/reference-glossary/#resource-id-validator","title":"Resource ID Validator","text":"<p>A Resource ID Validator is a Terraform Validation function which validates that the specified value is a Resource ID of the expected Type (for example a Subnet ID validator checks it\u2019s a Subnet ID).</p> <p>The value is parsed case-sensitively (in some cases, an optional case-insensitive validation function is also available) using the associated Resource ID Parser.</p> <p>This Resource ID Validator can then be used as a validation function within Terraform Schema fields as necessary - to confirm that the user-specified value (for example, for a Subnet ID) is actually the specified type (for example, a Subnet ID) and not another Resource ID or value (for example, a Virtual Network ID).</p> <p>These are generally (but not always) auto-generated - see Terraform Managed Resource ID\u2019s below for more information.</p>"},{"location":"topics/reference-glossary/#resource-manager-api","title":"Resource Manager API","text":"<p>Some Service Teams refer to this as \"Management Plane\".</p> <p>A Resource Manager API is used to provision resources within an Azure Subscription/Management Group, for example a Resource Group or a Virtual Machine.</p> <p>Whilst the Resource Manager API can be used to provision resources, resources within those are generally exposed via Data Plane APIs (see above) - for example Blobs within a Storage Account.</p>"},{"location":"topics/reference-glossary/#service-package","title":"Service Package","text":"<p>A Service Package is a grouping of Data Sources and Resources (and any other associated functionality) which are related together, for example <code>Cosmos</code> or <code>Compute</code>.</p> <p>Each Service Package contains a Service Registration which defines the Data Sources and Resources available within that Service Package.</p> <p>Whilst these tend to map 1:1 to Azure Resource Providers (for example the <code>cosmos</code> Service Package contains the CosmosDB resources) - some are intentionally split out where the Resource Provider (or Service Package) would otherwise be too large (for example the Network package has Load Balancers split out).</p>"},{"location":"topics/reference-glossary/#service-registration","title":"Service Registration","text":"<p>Each Service Package contains a Service Registration which defines the Data Sources and Resources available within that Service Package.</p> <p>This is either a Typed Service Registration or an Untyped Service Registration (documented below) - both available within the Typed Plugin SDK.</p> <p>Note that a Service Registration can be both a Typed and Untyped Service Registration by implementing both the Typed and Untyped Service Registration interfaces. This allows the mixing of both Typed and Untyped Data Sources and Resources within a Service Package.</p>"},{"location":"topics/reference-glossary/#state-migration","title":"State Migration","text":"<p>A State Migration is used when a resource has been changed to expect something different in the state than what previous version of the provider have written to it. An example of this is if Azure started to return a Resource ID value in a different case. rather than showing this during the plan, we can write a state migration to update the ID values transparently with no action required by a user. These are found in <code>services/service/migrations</code> and documentation on how to write them can be found in the Terraform Plugin SDK documentation.</p>"},{"location":"topics/reference-glossary/#terraform-managed-resource-id","title":"Terraform Managed Resource ID","text":"<p>A Terraform Managed Resource ID is a Resource ID defined in Terraform, rather than set by the Remote API.</p> <p>The Azure Provider is moving to use Terraform Managed Resource ID\u2019s for all resources, since these are known ahead of time - which avoids issues with API\u2019s changing these Resource ID\u2019s over time (either in casing, or renaming segments altogether).</p> <p>At present these are defined in a <code>resourceids.go</code> file within each Service Package, which generates a Resource ID Formatter, Parser and Validator for this Resource ID.</p>"},{"location":"topics/reference-glossary/#terraform-resource-data","title":"Terraform Resource Data","text":"<p>Terraform Resource Data is a wrapper around the values within either the Terraform Configuration/State, depending on when this is called.</p> <p>Values within the Resource Data can be accessed using <code>d.Get</code> (for example <code>d.Get(\u201csome_field\u201d).(string)</code>) and set using <code>d.Set</code> (for example <code>d.Set(\u201csome_field\u201d, \u201chello\u201d)</code>.</p>"},{"location":"topics/reference-glossary/#terraform-resource-id","title":"Terraform Resource ID","text":"<p>Each Data Source and Resource within Terraform has a Resource ID used to keep track of this resource, set at creation/import time.</p> <p>For a Resource this is set in the Create function after the resource has been successfully provisioned (or at Import time, when imported) - and then used in the Delete, Read and Update functions to look up this resource.</p> <p>Since Data Sources look up information about existing resources - and as such don\u2019t have a Create method - these instead set the Resource ID within the Read function.</p>"},{"location":"topics/reference-glossary/#typed-data-source","title":"Typed Data Source","text":"<p>A Typed Data Source is a Terraform Data Source built using the Typed Plugin SDK, allowing this Data Source to be defined using Native Go Types.</p>"},{"location":"topics/reference-glossary/#typed-resource","title":"Typed Resource","text":"<p>A Typed Resource is a Terraform Resource built using the Typed Plugin SDK, allowing this Resource to be defined using Native Go Types.</p>"},{"location":"topics/reference-glossary/#typed-plugin-sdk","title":"Typed Plugin SDK","text":"<p>The Typed Plugin SDK is an abstraction over the Terraform Plugin SDK housed within the AzureRM Provider repository - which allows Terraform Data Sources and Resources to be built using Native Go Types.</p> <p>The Typed Plugin SDK contains both Golang Interfaces for Data Sources and Resources (which allows verifying these are valid at compile-time) - and a wrapper around Terraform Resource Data which allows for values from the Terraform Configuration to be  Serialized/Deserialized into a Native Go Struct.</p> <p>More information can be found in the documentation for the Typed Plugin SDK.</p>"},{"location":"topics/reference-glossary/#typed-service-registration","title":"Typed Service Registration","text":"<p>A Typed Service Registration returns a list of the Typed Data Sources and Typed Resources which are available within that Service Package.</p> <p>This is implemented within the Typed Plugin SDK as the interface <code>TypedServiceRegistration</code> (see also: <code>TypedServiceRegistrationWithAGitHubLabel</code>).</p>"},{"location":"topics/reference-glossary/#untyped-data-source","title":"Untyped Data Source","text":"<p>An Untyped Data Source is a Terraform Data Source built using the Terraform Plugin SDK directly, which looks up information about an existing Resource. These are exposed as a function which returns an instance of the Plugin SDK\u2019s <code>Resource</code> struct - implementing whichever methods are necessary (generally, the Schema and Read/Timeouts functions).</p> <p>The Terraform Resource Data can be used to set fields into the Terraform State - and to set the ID using <code>d.SetId(\u201c\u201d)</code>.</p>"},{"location":"topics/reference-glossary/#untyped-resource","title":"Untyped Resource","text":"<p>An Untyped Resource is a Terraform Resource built using the Terraform Plugin SDK directly, which manages this Resource (through either creation/import onwards). These are exposed as a function which returns an instance of the Plugin SDK\u2019s <code>Resource</code> struct - implementing whichever methods are necessary (generally, the Schema and Create/Read/Update/Delete/Import/Timeouts functions).</p> <p>The Terraform Resource Data can be used to retrieve fields from the Terraform Configuration/set fields into the Terraform State - and to get/set the ID using <code>d.Id()</code> / <code>d.SetId(\u201c\u201d)</code>.</p>"},{"location":"topics/reference-glossary/#untyped-service-registration","title":"Untyped Service Registration","text":"<p>An Untyped Service Registration returns a list of the Untyped Data Sources and Untyped Resources which are available within that Service Package.</p> <p>This is implemented within the Typed Plugin SDK as the interface <code>UntypedServiceRegistration</code> (see also: <code>UntypedServiceRegistrationWithAGitHubLabel</code>).</p>"},{"location":"topics/reference-naming/","title":"Property Naming","text":"<p>As with naming variables, property naming can also be a laborious task. Given the nature of the provider careful consideration should be given to property names, since changing it is a non-negligible amount of effort.</p> <p>Whilst there are many cases where the property name can be taken over 1 to 1 from the Azure API, there are many instances where this is not the case.</p> <p>Here are some general guidelines you can turn to when naming properties:</p> <ul> <li> <p>The name should describe what the property is for succinctly, but as with many things a balance should be struck between too short or too long.</p> </li> <li> <p>Choose the officially marketed name for new properties over the ones used in the API if they differ.</p> </li> <li> <p>Abbreviations should not be used and the full words should be used instead e.g. </p> <p><code>resource_group_name</code> instead of <code>rg_name</code> or <code>virtual_machine</code> instead of <code>vm</code>.</p> </li> <li> <p>For blocks avoid redundant words in the name that don't add informational value e.g.</p> <p><code>firewall_properties</code> can be shortened to <code>firewall</code>, the same can apply to individual properties e.g. <code>email_address</code> to <code>email</code>.</p> </li> <li> <p>Properties for certificates or artifacts that must be in a certain format should be appended with the format e.g.</p> <p>A certificate that must be base64 encoded should be named <code>certificate_base64</code></p> </li> <li> <p>Similarly, properties that pertain to sizes or durations/windows/occurences should be appended with the appropriate unit of measure e.g.</p> <p><code>duration_in_seconds</code> or <code>size_in_gb</code></p> </li> <li> <p>Time properties that are not in the format of RFC3339 or are specified as UTC in the documentation should have that appended e.g.</p> <p><code>timestamp_in_utc</code></p> </li> <li> <p>For booleans these guidelines apply:</p> </li> <li> <p>As a general rule, booleans should be appended with <code>_enabled</code> e.g.</p> <p><code>public_network_access_enabled</code></p> </li> <li> <p>Booleans named <code>disableSomething</code> in the API should be flipped and exposed as <code>something_enabled</code> in the provider.</p> </li> <li> <p>Avoid redundant verbs like <code>is</code> at the beginning of the property e.g.</p> <p><code>is_storage_enabled</code> must be renamed to <code>storage_enabled</code>.</p> </li> <li> <p>Avoid double negatives which obfuscate the purpose of the property these should be removed and flipped e.g.</p> <p><code>no_storage_enabled</code> becomes <code>storage_enabled</code> or <code>block_user_upload_enabled</code> becomes <code>user_upload_enabled</code>.</p> </li> </ul>"},{"location":"topics/running-the-tests/","title":"Running the Tests","text":"<p>Note: Acceptance tests create real resources in Azure which often cost money to run.</p> <p>Acceptance Tests for each Data Source/Resource are located within a Service Package, as such the Acceptance Tests for a given Service Package can be run via:</p> <pre><code>make acctests SERVICE='&lt;service&gt;' TESTTIMEOUT='60m'\n</code></pre> <p>However as many Service Packages contain multiple resources, you can opt to only run a subset by specifying the test prefix/filter to run as shown below:</p> <pre><code>make acctests SERVICE='&lt;service&gt;' TESTARGS='-run=&lt;nameOfTheTest&gt;' TESTTIMEOUT='60m'\n</code></pre> <ul> <li><code>&lt;service&gt;</code> is the name of the folder which contains the file with the test(s) you want to run. The available folders are found in <code>azurerm/internal/services/</code>. So examples are <code>mssql</code>, <code>compute</code> or <code>mariadb</code></li> <li><code>&lt;nameOfTheTest&gt;</code> should be self-explanatory as it is the name of the test you want to run. An example could be <code>TestAccMsSqlServerExtendedAuditingPolicy_basic</code>. Since <code>-run</code> can be used with regular expressions you can use it to specify multiple tests like in <code>TestAccMsSqlServerExtendedAuditingPolicy_</code> to run all tests that match that expression</li> </ul> <p>The following Environment Variables must be set in your shell prior to running acceptance tests:</p> <ul> <li><code>ARM_CLIENT_ID</code></li> <li><code>ARM_CLIENT_SECRET</code></li> <li><code>ARM_SUBSCRIPTION_ID</code></li> <li><code>ARM_TENANT_ID</code></li> <li><code>ARM_ENVIRONMENT</code></li> <li><code>ARM_METADATA_HOST</code></li> <li><code>ARM_TEST_LOCATION</code></li> <li><code>ARM_TEST_LOCATION_ALT</code></li> <li><code>ARM_TEST_LOCATION_ALT2</code></li> </ul> <p>Note: Acceptance tests create real resources in Azure which often cost money to run.</p>"},{"location":"topics/schema-design-considerations/","title":"Schema Design Considerations","text":"<p>Whilst it is acceptable in certain cases to map the schema of a new resource or feature when extending an existing resource, one-to-one from the Azure API, in the majority of cases more consideration needs to be given how to expose the Azure API in Terraform so that the provider presents a consistent and intuitive experience to the end user.</p> <p>Below are a list of common patterns found in the Azure API and how these typically get mapped within Terraform.</p>"},{"location":"topics/schema-design-considerations/#features-that-are-toggled-by-the-property-enabled","title":"Features that are toggled by the property <code>Enabled</code>","text":"<p>It is commonplace for features to be toggled on and off by an <code>Enabled</code> property within an object in the SDK used to interact with the Azure API. See the examples below.</p> <p>Example A. <pre><code>type ManagedClusterStorageProfileBlobCSIDriver struct {\nEnabled *bool `json:\"enabled,omitempty\"`\n}\n</code></pre></p> <p>Example B. <pre><code>type ManagedClusterWorkloadAutoScalerProfileVerticalPodAutoscaler struct {\nControlledValues ControlledValues `json:\"controlledValues\"`\nEnabled          bool             `json:\"enabled\"`\nUpdateMode       UpdateMode       `json:\"updateMode\"`\n}\n</code></pre></p> <p>Although there are still resources within the provider where this property is exposed in the Terraform schema, the provider is moving away from this and instead translates this behaviour in one of two ways.</p> <p>In cases where <code>Enabled</code> is the only field required to turn a feature on and off we opt to flatten the block into a single top level property (or higher level property if already nested inside a block). So in the case of Example A, this would become:</p> <pre><code>\"storage_blob_driver_enabled\": {\nType:     pluginsdk.TypeBool,\nOptional: true,\nDefault:  false,\n},\n</code></pre> <p>For features that can accept or require configuration, i.e. the object contains additional properties other than <code>Enabled</code> like in Example B, the behaviour should be such that when the block is present the feature is enabled, and when it is absent it is disabled. The corresponding Terraform schema would be as follows:</p> <pre><code>\"vertical_pod_autoscaler\": {\nType:     pluginsdk.TypeList,\nOptional: true,\nMaxItems: 1,\nElem: &amp;pluginsdk.Resource{\nSchema: map[string]*pluginsdk.Schema{\n\"update_mode\": {\nType:     pluginsdk.TypeString,\nRequired: true,\nValidateFunc: validation.StringInSlice([]string{\nstring(managedclusters.UpdateModeAuto),\nstring(managedclusters.UpdateModeInitial),\nstring(managedclusters.UpdateModeRecreate),\n}, false),\n},\n\"controlled_values\": {\nType:     pluginsdk.TypeString,\nRequired: true,\nValidateFunc: validation.StringInSlice([]string{\nstring(managedclusters.ControlledValuesRequestsAndLimits),\nstring(managedclusters.ControlledValuesRequestsOnly),\n}, false),\n},\n},\n},\n},\n</code></pre> <p>There are instances where configuration properties for a feature is optional, as shown below.</p> <p>Example C. <pre><code>type ManagedClusterStorageProfileDiskCSIDriver struct {\nEnabled *bool   `json:\"enabled,omitempty\"`\nVersion *string `json:\"version,omitempty\"`\n}\n</code></pre></p> <p>In cases like these one option is to flatten the block into two top level properties.</p> <pre><code>\"storage_disk_driver_enabled\": {\nType:     pluginsdk.TypeBool,\nOptional: true,\nDefault:  false,\n},\n\n\"storage_disk_driver_version\": {\nType:     pluginsdk.TypeString,\nOptional: true,\nDefault:  \"V1\",\nValidateFunc: validation.StringInSlice([]string{\n\"V1\",\n\"V2\",\n}, false),\n},\n</code></pre> <p>Depending on the behaviour of the Azure API and the default set by it, a worthwhile alternative is to set the property as required in the Terraform schema, to avoid having to set empty blocks to enable features.</p> <pre><code>\"storage_disk_driver\": {\nType:     pluginsdk.TypeList,\nOptional: true,\nMaxItems: 1,\nElem: &amp;pluginsdk.Resource{\nSchema: map[string]*pluginsdk.Schema{\n\"version\": {\nType:     pluginsdk.TypeString,\nRequired: true,\nValidateFunc: validation.StringInSlice([]string{\n\"V1\",\n\"V2\",\n}, false),\n},\n},\n},\n},\n</code></pre>"},{"location":"topics/schema-design-considerations/#the-none-value-or-similar","title":"The <code>None</code> value or similar","text":"<p>Many Azure APIs and services will accept the values like <code>None</code>, <code>Off</code>, or <code>Default</code> as a default value and expose it as a constant in the API specification. </p> <pre><code>    \"shutdownOnIdleMode\": {\n      \"type\": \"string\",\n      \"enum\": [\n        \"None\",\n        \"UserAbsence\",\n        \"LowUsage\"\n      ],\n</code></pre> <p>Whilst it isn't uncommon to stumble across older resources in the provider that expose and accept these as a valid values, the provider is moving away from this pattern, since Terraform has its own null type i.e. by omitting the field. Existing <code>None</code>, <code>Off</code> or <code>Default</code> values within the provider are planned for removal in version 4.0.</p> <p>This ultimately means that the end user doesn't need to bloat their configuration with superfluous information that is implied through the omission of information.</p> <p>The resulting schema in Terraform would look as follows and also requires a conversion between the Terraform null value and <code>None</code> within the Create and Read functions.</p> <pre><code>// How the property is exposed in the schema\n\"shutdown_on_idle\": {\nType:     pluginsdk.TypeString,\nOptional: true,\nValidateFunc: validation.StringInSlice([]string{\nstring(labplan.ShutdownOnIdleModeUserAbsence),\nstring(labplan.ShutdownOnIdleModeLowUsage),\n// NOTE: Whilst the `None` value exists it's handled in the Create/Update and Read functions.\n// string(labplan.ShutdownOnIdleModeNone),\n}, false),\n},\n\n// Normalising in the create or expand function\nfunc (r resource) Create() sdk.ResourceFunc {\n\n...\n\nvar config resourceModel\nif err := metadata.Decode(&amp;config); err != nil {\nreturn fmt.Errorf(\"decoding: %+v\", err)\n}\n\n// The resource property shutdown_on_idle maps to the attribute shutdownOnIdle in the defined model for a typed resource in this example\nshutdownOnIdle := string(labplan.ShutdownOnIdleModeNone)\nif v := model.ShutdownOnIdle; v != \"\" {\nshutdownOnIdle = v\n}\n\n...\n\n}\n\n// Normalising in the read or flatten function\nfunc (r resource) Read() sdk.ResourceFunc {\n\n...\n\nshutdownOnIdle := \"\"\nif v := props.ShutdownOnIdle; v != nil &amp;&amp; v != string(labplan.ShutdownOnIdleModeNone) {\nshutdownOnIdle = string(*v)\n}\n\nstate.ShutdownOnIdle = shutdownOnIdle\n\n...\n\n}\n</code></pre>"},{"location":"topics/schema-design-considerations/#the-type-field","title":"The <code>type</code> field","text":"<p>The Azure API makes use of classes and inheritance through discriminator types defined in the REST API specifications. A strong indicator that a resource is actually a discriminated type is through the definition of a <code>type</code> or <code>kind</code> property.</p> <p>Rather than exposing a generic resource with all the possible fields for all the possible different <code>type</code>'s, we intentionally opt to split these resources by the <code>type</code> to improve the user experience. This means we can only output the relevant fields for this <code>type</code> which in turn allows us to provide more granular validation etc.</p> <p>Whilst there is a trade-off here, since this means that we have to maintain more Data Sources/Resources, this is a worthwhile trade-off since each of these resources only exposes the fields which are relevant for this resource, meaning the logic is far simpler than trying to maintain a generic resource and pushing the complexity onto end-users.</p> <p>Taking the Data Factory Linked Service resources as an example which could have all of possible types defined below, each requiring a different set of inputs:</p> <pre><code>\"type\": {\nType:     pluginsdk.TypeString,\nRequired: true,\nValidateFunc: validation.StringInSlice([]string{\nstring(datafactory.TypeBasicLinkedServiceTypeAzureBlobStorage),\nstring(datafactory.TypeBasicLinkedServiceTypeAzureDatabricks),\nstring(datafactory.TypeBasicLinkedServiceTypeAzureFileStorage),\nstring(datafactory.TypeBasicLinkedServiceTypeAzureFunction),\nstring(datafactory.TypeBasicLinkedServiceTypeAzureSearch),\n...\n}, false),\n},\n</code></pre> <p>Would be better exposed as the following resources: - <code>azurerm_data_factory_linked_service_azure_blob_storage</code> - <code>azurerm_data_factory_linked_service_azure_databricks</code> - <code>azurerm_data_factory_linked_service_azure_file_storage</code> - <code>azurerm_data_factory_linked_service_azure_function</code> - <code>azurerm_data_factory_linked_service_azure_search</code></p> <p>...</p>"}]}